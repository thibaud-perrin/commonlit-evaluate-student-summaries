{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "0a14353b-46a1-4c60-9ee7-080174af9aa7",
         "metadata": {},
         "source": [
            "# Sentence Transformer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "9c8f10e2-148a-44e1-8cf6-748a75601885",
         "metadata": {},
         "outputs": [],
         "source": [
            "import copy\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "import torch.optim as optim\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "from datasets import load_from_disk\n",
            "from transformers import DebertaV2Tokenizer, DebertaV2Model\n",
            "\n",
            "import matplotlib.pyplot as plt \n",
            "import seaborn as sns\n",
            "%matplotlib inline"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e214c448-b292-4cd7-92e6-740be40bc11d",
         "metadata": {},
         "source": [
            "## GPU"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "959cac82-9842-4968-9597-4c8324936e66",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "zsh:1: command not found: nvidia-smi\n"
               ]
            }
         ],
         "source": [
            "!nvidia-smi"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "eceddb8b-556e-4e20-8137-a4e77efa0490",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "device(type='cpu')"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Check if CUDA is available, else use CPU\n",
            "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
            "device"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c5e1345e-a55c-4636-b5ee-1078da5d812d",
         "metadata": {},
         "source": [
            "### Hyperparameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "05b6a852-9309-4923-848c-1eda295814ed",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Hyperparameters\n",
            "LEARNING_RATE = 0.000005\n",
            "BATCH_SIZE = 24\n",
            "EPOCHS = 200"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a2aa67ca-52c8-409e-8862-dac0997bafe0",
         "metadata": {},
         "source": [
            "## Path"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a1fd958f-82f1-4f6b-9a00-97c41e225c30",
         "metadata": {},
         "source": [
            "## Generate dataset and batch"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "fd6d7c30-5744-4c0d-824d-dcc667e50a9f",
         "metadata": {},
         "outputs": [],
         "source": [
            "class PromptDataset(Dataset):\n",
            "\n",
            "    def __init__(self, dataset, device):\n",
            "        self.dataset = dataset\n",
            "        self.device = device\n",
            "\n",
            "    def deserialize_array(self, binary_string, dtype, shape):\n",
            "        return np.frombuffer(binary_string, dtype=dtype).reshape(shape)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        data = self.dataset[index]\n",
            "        # retrieve values\n",
            "        student_id = data['student_id']\n",
            "        prompt_id = data['prompt_id']\n",
            "        sentence = data['sentence']\n",
            "        t_q_a_embeddings = torch.tensor(self.deserialize_array(data['t_q_a_embeddings'], np.float32, (768,))).to(self.device)\n",
            "        embeddings_text = torch.tensor(self.deserialize_array(data['embeddings_text'], np.float32, (768,))).to(self.device)\n",
            "        content = torch.tensor(data['content']).to(self.device)\n",
            "        wording = torch.tensor(data['wording']).to(self.device)\n",
            "        normalized_lexical_density = torch.tensor(data['normalized_lexical_density']).unsqueeze(0).to(self.device)\n",
            "        normalized_spell_checker = torch.tensor(data['normalized_spell_checker']).unsqueeze(0).to(self.device)\n",
            "        normalized_tf_idf_question_score = torch.tensor(data['normalized_tf_idf_question_score']).unsqueeze(0).to(self.device)\n",
            "        normalized_avg_word_length = torch.tensor(data['normalized_avg_word_length']).unsqueeze(0).to(self.device)\n",
            "        normalized_smog_index = torch.tensor(data['normalized_smog_index']).unsqueeze(0).to(self.device)\n",
            "        normalized_coleman_liau_index = torch.tensor(data['normalized_coleman_liau_index']).unsqueeze(0).to(self.device)\n",
            "        normalized_flesch_reading_ease = torch.tensor(data['normalized_flesch_reading_ease']).unsqueeze(0).to(self.device)\n",
            "        \n",
            "        return {\n",
            "            'student_id': student_id,\n",
            "            'prompt_id': prompt_id,\n",
            "            'sentence': sentence,\n",
            "            't_q_a_embeddings': t_q_a_embeddings,\n",
            "            'embeddings_text': embeddings_text,\n",
            "            'content': content,\n",
            "            'wording': wording,\n",
            "            'normalized_lexical_density': normalized_lexical_density,\n",
            "            'normalized_spell_checker': normalized_spell_checker,\n",
            "            'normalized_tf_idf_question_score': normalized_tf_idf_question_score,\n",
            "            'normalized_avg_word_length': normalized_avg_word_length,\n",
            "            'normalized_smog_index': normalized_smog_index,\n",
            "            'normalized_coleman_liau_index': normalized_coleman_liau_index,\n",
            "            'normalized_flesch_reading_ease': normalized_flesch_reading_ease,\n",
            "        }\n",
            "\n",
            "    def __len__(self) -> int :\n",
            "        return self.dataset.num_rows"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "843e316c-df6c-485f-8561-6f890c556f87",
         "metadata": {},
         "outputs": [],
         "source": [
            "class DataLoaderFactory():\n",
            "\n",
            "    def __init__(self, path:str = './data/hugging_face', batch_size = 12, device = 'cpu'):\n",
            "        self.batch_size = batch_size\n",
            "        self.dataset = load_from_disk(path, keep_in_memory=True)\n",
            "        self.device = device\n",
            "\n",
            "        print(\"1. Loading dataset: ...\", end=\"\")\n",
            "        dataset = load_from_disk(path, keep_in_memory=True)\n",
            "        print(\"\\r1. Loading dataset: done ✔️\")\n",
            "\n",
            "        print(\"2. Split datasets: ...\", end=\"\")\n",
            "        train_validation_splits = self.dataset['train'].train_test_split(test_size=0.3)\n",
            "        validation_test_splits = train_validation_splits['test'].train_test_split(test_size=0.4)\n",
            "        print(\"\\r2. Preprocess datasets: done ✔️\")\n",
            "\n",
            "        print(\"3. Split datasets: ...\", end=\"\")\n",
            "        self.train_data = PromptDataset(train_validation_splits['train'], self.device)\n",
            "        self.val_data = PromptDataset(validation_test_splits['train'], self.device)\n",
            "        self.test_data = PromptDataset(validation_test_splits['test'], self.device)\n",
            "        print(\"\\r3. Split datasets: done ✔️\")\n",
            "\n",
            "        self.dataloader_train = DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n",
            "        self.dataloader_val = DataLoader(self.val_data, batch_size=batch_size, shuffle=True)\n",
            "        self.dataloader_test = DataLoader(self.test_data, batch_size=batch_size, shuffle=True)\n",
            "    \n",
            "    \n",
            "    def __len__(self) -> int :\n",
            "        print(\"\\033[95m\\033[1m\\033[4mNumber of data by datasets splits\\033[0m\")\n",
            "        print(f\"Train\\t\\t: {len(self.train_data)}\\t-> {len(self.train_data)/self.batch_size}\")\n",
            "        print(f\"Validation\\t: {len(self.val_data)}\\t\\t-> {len(self.val_data)/self.batch_size}\")\n",
            "        print(f\"Test\\t\\t: {len(self.test_data)}\\t\\t-> {len(self.test_data)/self.batch_size}\")\n",
            "        total = len(self.train_data) + len(self.val_data)\n",
            "        print(f\"Total\\t\\t: {total}\")\n",
            "        return total\n",
            "\n",
            "    def get_batch(self, split):\n",
            "        # choose the correct dataloader\n",
            "        if split == 'train':\n",
            "            dataloader = self.dataloader_train\n",
            "        elif split == 'val':\n",
            "            dataloader = self.dataloader_val\n",
            "        else:\n",
            "            dataloader = self.dataloader_test\n",
            "\n",
            "        for batch in dataloader:\n",
            "            # Move tensors to device\n",
            "            batch_on_device = {k: v for k, v in batch.items()}\n",
            "            yield batch_on_device"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d18f4fc8-1830-4fab-ae74-d12fb945f374",
         "metadata": {},
         "source": [
            "### Load the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "f67182de-ccb8-4f77-87e0-5c88be245435",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "1. Loading dataset: done ✔️\n",
                  "2. Preprocess datasets: done ✔️\n",
                  "3. Split datasets: done ✔️\n",
                  "\u001b[95m\u001b[1m\u001b[4mNumber of data by datasets splits\u001b[0m\n",
                  "Train\t\t: 5015\t-> 208.95833333333334\n",
                  "Validation\t: 1290\t\t-> 53.75\n",
                  "Test\t\t: 860\t\t-> 35.833333333333336\n",
                  "Total\t\t: 6305\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "6305"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dataset = DataLoaderFactory(device=device, batch_size=BATCH_SIZE)\n",
            "len(dataset)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1c5e512f-1fad-4c54-80c5-c0500a25f086",
         "metadata": {},
         "source": [
            "### Testing the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "fded6cee-24b5-4d28-a3df-a857fd1336c7",
         "metadata": {},
         "outputs": [],
         "source": [
            "batch = dataset.get_batch('train')\n",
            "nb = next(batch)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "1ae8f919-4ba2-46be-be03-d47b248ddd70",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "student_id:              24\n",
                  "prompt_id:               24\n",
                  "sentence:                24\n",
                  "t_q_a_embeddings:        torch.Size([24, 768])\n",
                  "embeddings_text:         torch.Size([24, 768])\n",
                  "content:                 torch.Size([24])\n",
                  "wording:                 torch.Size([24])\n",
                  "normalized_lexical_density:torch.Size([24, 1])\n",
                  "normalized_spell_checker:torch.Size([24, 1])\n",
                  "normalized_tf_idf_question_score:torch.Size([24, 1])\n",
                  "normalized_avg_word_length:torch.Size([24, 1])\n",
                  "normalized_smog_index:   torch.Size([24, 1])\n",
                  "normalized_coleman_liau_index:torch.Size([24, 1])\n",
                  "normalized_flesch_reading_ease:torch.Size([24, 1])\n"
               ]
            }
         ],
         "source": [
            "print(f\"{'student_id:':<25}{len(nb['student_id'])}\")\n",
            "print(f\"{'prompt_id:':<25}{len(nb['prompt_id'])}\")\n",
            "print(f\"{'sentence:':<25}{len(nb['sentence'])}\")\n",
            "print(f\"{'t_q_a_embeddings:':<25}{nb['t_q_a_embeddings'].shape}\")\n",
            "print(f\"{'embeddings_text:':<25}{nb['embeddings_text'].shape}\")\n",
            "print(f\"{'content:':<25}{nb['content'].shape}\")\n",
            "print(f\"{'wording:':<25}{nb['wording'].shape}\")\n",
            "print(f\"{'normalized_lexical_density:':<25}{nb['normalized_lexical_density'].shape}\")\n",
            "print(f\"{'normalized_spell_checker:':<25}{nb['normalized_spell_checker'].shape}\")\n",
            "print(f\"{'normalized_tf_idf_question_score:':<25}{nb['normalized_tf_idf_question_score'].shape}\")\n",
            "print(f\"{'normalized_avg_word_length:':<25}{nb['normalized_avg_word_length'].shape}\")\n",
            "print(f\"{'normalized_smog_index:':<25}{nb['normalized_smog_index'].shape}\")\n",
            "print(f\"{'normalized_coleman_liau_index:':<25}{nb['normalized_coleman_liau_index'].shape}\")\n",
            "print(f\"{'normalized_flesch_reading_ease:':<25}{nb['normalized_flesch_reading_ease'].shape}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "420d85e7-b1e4-4d22-b043-ee9374286d04",
         "metadata": {},
         "source": [
            "## Training model"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c0c70332-9c16-499c-9fc3-734f72e2ecf4",
         "metadata": {},
         "source": [
            "1. **Input Layer:** Accept the embeddings of the question, text, and answer. This would result in three separate input layers, each of dimension `[batch_size, embedding_size]`.\n",
            "2. **Concatenate Layer:** Concatenate the embeddings along the feature axis. This results in `[batch_size, 3 * embedding_size]` dimensions.\n",
            "3. **Dense Layers:** Add a couple of Dense layers with suitable dropout layers in between for regularization. For instance:\n",
            "    - Dense layer with `1024` units, `ReLU` activation.\n",
            "    - Dropout layer with rate `0.5`.\n",
            "    - Dense layer with `512` units, ReLU activation.\n",
            "    - Another Dropout layer with rate `0.5`.\n",
            "4. **Output Layer:** Single Dense layer with `2` units (since you want two values between -1 and 1) and a `tanh` activation function.\n",
            "5. **Loss Function:** If the output of your model is a vector with two values between -1 and 1, then you're essentially dealing with multi-output regression. You can use `Mean Squared Error` or `Mean Absolute Error`, but it'll be applied to each output.\n",
            "6. **Optimizer:** Remains the same; options include `Adam`, `RMSprop`, and `SGD`."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "cf7a39cc-86ee-419b-b045-12f1a9d8dac1",
         "metadata": {},
         "source": [
            "## Utils"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "9565edec-5034-4e98-baa3-7f9e8c466857",
         "metadata": {},
         "outputs": [],
         "source": [
            "class DebertaV3Batch(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(DebertaV3Batch, self).__init__()\n",
            "        # Load the tokenizer and model\n",
            "        self.tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
            "        self.model = DebertaV2Model.from_pretrained('microsoft/deberta-v3-base')\n",
            "    \n",
            "\n",
            "    def encode(self, sentences):\n",
            "        # Tokenize sentences\n",
            "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
            "        # Compute token embeddings\n",
            "        with torch.no_grad():\n",
            "            model_output = self.model(**encoded_input)\n",
            "\n",
            "        # Only take the embeddings of the [CLS] token (or use the mean of the token embeddings if desired)\n",
            "        sentence_embeddings = model_output.last_hidden_state[:, 0, :]\n",
            "        \n",
            "        return sentence_embeddings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "35ee62c9-4c41-479d-a208-0e508c11e946",
         "metadata": {},
         "outputs": [],
         "source": [
            "class DebertaV3(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(DebertaV3, self).__init__()\n",
            "        # Load the tokenizer and model\n",
            "        self.tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
            "        self.model = DebertaV2Model.from_pretrained('microsoft/deberta-v3-base')\n",
            "\n",
            "\n",
            "    def sliding_window(self, text, window_size=512, overlap_size=256):\n",
            "        tokenized_text = self.tokenizer(text, return_tensors=\"pt\", truncation=False, padding=False)[\"input_ids\"][0]\n",
            "        windows = []\n",
            "        for start_idx in range(0, len(tokenized_text) - window_size + 1, window_size - overlap_size):\n",
            "            end_idx = start_idx + window_size\n",
            "            windows.append(tokenized_text[start_idx:end_idx])\n",
            "        return windows\n",
            "\n",
            "    def process_windows(self, windows):\n",
            "        embeddings = []\n",
            "        for window in windows:\n",
            "            inputs = {\"input_ids\": window.unsqueeze(0)}\n",
            "            outputs = self.model(**inputs)\n",
            "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
            "            embeddings.append(cls_embedding)\n",
            "        return embeddings\n",
            "    \n",
            "\n",
            "    def encode(self, sentences):\n",
            "        # Tokenize sentences\n",
            "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
            "        # Compute token embeddings\n",
            "        with torch.no_grad():\n",
            "            model_output = self.model(**encoded_input)\n",
            "\n",
            "        if len(encoded_input['input_ids'][0]) > 512:\n",
            "            windows = self.sliding_window(text)\n",
            "            window_embeddings = self.process_windows(windows)\n",
            "            \n",
            "            # Optionally, you can aggregate the window embeddings to get a single embedding for the entire text\n",
            "            # For example, by averaging:\n",
            "            average_embedding = torch.mean(torch.cat(window_embeddings), dim=0)\n",
            "            return average_embedding\n",
            "        else:\n",
            "            # Only take the embeddings of the [CLS] token (or use the mean of the token embeddings if desired)\n",
            "            sentence_embeddings = model_output.last_hidden_state[:, 0, :]\n",
            "            \n",
            "            return sentence_embeddings[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "b9381011-354c-4a66-aa20-565a15ff9bc3",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            }
         ],
         "source": [
            "deberta = DebertaV3()\n",
            "debertaBatch = DebertaV3Batch()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e151c3c0-9d49-423a-9347-e7ed526bdf18",
         "metadata": {},
         "source": [
            "### Define the Model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "2c51e654-671e-496f-aa2d-c6668fdd8caf",
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Define the Model\n",
            "# class QA_Score_Model(nn.Module):\n",
            "#     def __init__(self, input_dim=3*768+7, dropout_rate=0.5):\n",
            "#         super(QA_Score_Model, self).__init__()\n",
            "\n",
            "#         # Dense Layers\n",
            "#         self.fc1 = nn.Linear(input_dim, 1024)\n",
            "#         self.fc2 = nn.Linear(1024, 512)\n",
            "#         self.fc3 = nn.Linear(512, 2)  # Output 2 values for each instance\n",
            "\n",
            "#         # Dropout\n",
            "#         self.dropout = nn.Dropout(dropout_rate)\n",
            "\n",
            "#     def forward(self, x):\n",
            "#         x = F.relu(self.fc1(x))\n",
            "#         if self.training:\n",
            "#             x = self.dropout(x)\n",
            "#         x = F.relu(self.fc2(x))\n",
            "#         if self.training:\n",
            "#             x = self.dropout(x)\n",
            "#         x = torch.tanh(self.fc3(x))  # tanh to get outputs in range [-1, 1]\n",
            "#         return x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "3cd958cb-ca28-4a23-9910-93c28ac51584",
         "metadata": {},
         "outputs": [],
         "source": [
            "class QA_Score_Model(nn.Module):\n",
            "    def __init__(self, embedding_dim, dropout_rate=0.5):\n",
            "        super(QA_Score_Model, self).__init__()\n",
            "\n",
            "        # Embedding processors\n",
            "        self.fc_text = nn.Linear(embedding_dim, 256)\n",
            "        self.fc_t_q_a = nn.Linear(embedding_dim, 256)\n",
            "\n",
            "        # Scalar Processors\n",
            "        self.fc_lexical = nn.Linear(1, 16)\n",
            "        self.fc_spell = nn.Linear(1, 16)\n",
            "        self.fc_tfidf = nn.Linear(1, 16)\n",
            "        self.fc_avg_word_length = nn.Linear(1, 16)\n",
            "        self.fc_smog = nn.Linear(1, 16)\n",
            "        self.fc_coleman = nn.Linear(1, 16)\n",
            "        self.fc_flesch = nn.Linear(1, 16)\n",
            "\n",
            "        # Dropout layers\n",
            "        self.dropout = nn.Dropout(dropout_rate)\n",
            "\n",
            "        # Shared Dense Layers\n",
            "        self.fc1 = nn.Linear(256*2 + 16*7, 512)\n",
            "        self.fc2 = nn.Linear(512, 256)\n",
            "        \n",
            "        # Output Layers\n",
            "        self.out_content = nn.Linear(256, 1)\n",
            "        self.out_wording = nn.Linear(256, 1)\n",
            "        \n",
            "    def forward(self, text, t_q_a, features):\n",
            "        lexical, spell, tfidf, avg_word_length, smog, coleman, flesch = features\n",
            "        # Pass through convolutional layers\n",
            "        x_text = F.relu(self.fc_text(text))\n",
            "        x_t_q_a = F.relu(self.fc_t_q_a(t_q_a))\n",
            "\n",
            "        # Pass through scalar processors\n",
            "        x_lexical = F.relu(self.fc_lexical(lexical))\n",
            "        x_spell = F.relu(self.fc_spell(spell))\n",
            "        x_tfidf = F.relu(self.fc_tfidf(tfidf))\n",
            "        x_avg_word_length = F.relu(self.fc_avg_word_length(avg_word_length))\n",
            "        x_smog = F.relu(self.fc_smog(smog))\n",
            "        x_coleman = F.relu(self.fc_coleman(coleman))\n",
            "        x_flesch = F.relu(self.fc_flesch(flesch))\n",
            "        \n",
            "        # Concatenate\n",
            "        x = torch.cat((x_text, x_t_q_a, x_lexical, x_spell, x_tfidf, x_avg_word_length, x_smog, x_coleman, x_flesch), dim=1)\n",
            "        \n",
            "        # Pass through shared dense layers with dropout\n",
            "        x = F.relu(self.fc1(x))\n",
            "        x = self.dropout(x)\n",
            "        x = F.relu(self.fc2(x))\n",
            "        x = self.dropout(x)\n",
            "        \n",
            "        # Output\n",
            "        content = self.out_content(x)\n",
            "        wording = self.out_wording(x)\n",
            "        \n",
            "        return torch.cat((content, wording), dim=1).to(device)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "aa399d64-ba3a-41b4-ae4d-d699d3a6be37",
         "metadata": {},
         "source": [
            "### MCRMSE loss"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "id": "11708a30-f4f4-41bc-b759-918d56b374a3",
         "metadata": {},
         "outputs": [],
         "source": [
            "class MCRMSELoss(nn.Module):\n",
            "    def __init__(self):\n",
            "        super(MCRMSELoss, self).__init__()\n",
            "\n",
            "    def forward(self, y_true, y_pred):\n",
            "        colwise_mse = torch.mean(torch.square(y_true - y_pred), dim=0)\n",
            "        return torch.mean(torch.sqrt(colwise_mse), dim=0)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "id": "70e23974-ac03-4d23-a34a-251cf416c730",
         "metadata": {},
         "outputs": [],
         "source": [
            "def MCRMSE(targets, predictions):\n",
            "    \"\"\"\n",
            "    Compute the Mean Columnwise Root Mean Squared Error.\n",
            "    \n",
            "    Parameters:\n",
            "    - targets: Actual target values\n",
            "    - predictions: Model's predictions\n",
            "    \n",
            "    Returns:\n",
            "    - Mean Columnwise RMSE\n",
            "    \"\"\"\n",
            "    # Compute squared error\n",
            "    mse = torch.mean((targets - predictions) ** 2, dim=0)\n",
            "    \n",
            "    # Take square root of each column's MSE\n",
            "    rmse = torch.sqrt(mse)\n",
            "    \n",
            "    # Compute mean of RMSE across all columns\n",
            "    mcrmse = torch.mean(rmse)\n",
            "    \n",
            "    return mcrmse"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "357d2d50-f523-4794-b993-49bf5497a153",
         "metadata": {},
         "source": [
            "### Create an instance of the model, loss function and the optimizer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "11708a30-f4f4-41bc-b759-918d56b374a3",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Create an instance of the model, loss function and the optimizer\n",
            "model = QA_Score_Model(768)\n",
            "model = model.to(device)\n",
            "criterion = MCRMSELoss()  # Mean Absolute Error less sensitive to outliers # MSELoss Mean Squared Error Loss\n",
            "# criterion = nn.L1Loss()  # Mean Absolute Error less sensitive to outliers # MSELoss Mean Squared Error Loss\n",
            "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "76493c03-5a20-4658-80c6-31a1bcb5c41f",
         "metadata": {},
         "source": [
            "### Training loop"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "id": "51c3c6ec-b433-4efa-a5a5-8e8324d87836",
         "metadata": {},
         "outputs": [],
         "source": [
            "def training_loop(model, dataset, epoch):\n",
            "    model = model.train()\n",
            "    \n",
            "    total_train_loss = 0.0\n",
            "    # total_train_mcrmse = 0.0\n",
            "    \n",
            "    batchs = dataset.get_batch('train')\n",
            "    \n",
            "    num_train_batches = len(dataset.train_data) // BATCH_SIZE\n",
            "    for i, batch in enumerate(batchs):\n",
            "        # Get the batch data\n",
            "        student_id = batch['student_id']\n",
            "        prompt_id = batch['prompt_id']\n",
            "        t_q_a_embeddings = batch['t_q_a_embeddings']\n",
            "        embeddings_text = batch['embeddings_text']\n",
            "        content = batch['content']\n",
            "        wording = batch['wording']\n",
            "        normalized_lexical_density = batch['normalized_lexical_density']\n",
            "        normalized_spell_checker = batch['normalized_spell_checker']\n",
            "        normalized_tf_idf_question_score = batch['normalized_tf_idf_question_score']\n",
            "        normalized_avg_word_length = batch['normalized_avg_word_length']\n",
            "        normalized_smog_index = batch['normalized_smog_index']\n",
            "        normalized_coleman_liau_index = batch['normalized_coleman_liau_index']\n",
            "        normalized_flesch_reading_ease = batch['normalized_flesch_reading_ease']\n",
            "        \n",
            "        # create input targets\n",
            "        input_data = torch.cat(\n",
            "            (\n",
            "                embeddings_text,\n",
            "                embeddings_question,\n",
            "                embeddings_answer\n",
            "            ), dim=1).to(device)\n",
            "        targets = torch.stack(\n",
            "            (\n",
            "                content,\n",
            "                wording\n",
            "            ), dim=1).to(device)\n",
            "        \n",
            "        # Zero the gradients\n",
            "        optimizer.zero_grad()\n",
            "\n",
            "        # Forward pass\n",
            "        features = (normalized_lexical_density, \\\n",
            "                    normalized_spell_checker, \\\n",
            "                    normalized_tf_idf_question_score, \\\n",
            "                    normalized_avg_word_length, \\\n",
            "                    normalized_smog_index, \\\n",
            "                    normalized_coleman_liau_index, \\\n",
            "                    normalized_flesch_reading_ease \\\n",
            "                   )\n",
            "        outputs = model(embeddings_text, t_q_a_embeddings, features)\n",
            "\n",
            "        # Loss\n",
            "        loss = criterion(targets, outputs)\n",
            "        # eval_metric = MCRMSE(targets, outputs)\n",
            "\n",
            "        # Backward pass and optimization\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "\n",
            "        # Print loss (you might want to print every N batches, not every batch)\n",
            "        print(f\"\\rEpoch [{epoch + 1}/{EPOCHS}], Batch [{i}/{num_train_batches}], Loss: {loss.item()}\", end=\"\")\n",
            "        # print(f\"\\rEpoch [{epoch + 1}/{EPOCHS}], Batch [{i}/{num_train_batches}], Loss: {loss.item()}, MCRMSE: {eval_metric.item()}\", end=\"\")\n",
            "        \n",
            "\n",
            "        total_train_loss += loss.item()\n",
            "        # total_train_mcrmse += eval_metric.item()\n",
            "\n",
            "    avg_train_loss = total_train_loss / num_train_batches\n",
            "    # avg_train_mcrmse = total_train_mcrmse / num_train_batches\n",
            "\n",
            "    # return model, avg_train_loss, avg_train_mcrmse\n",
            "    return model, avg_train_loss"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "3938650b-cf46-4e24-88ea-1d46cc827f3f",
         "metadata": {},
         "source": [
            "### Validation loop"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "id": "50b820d0-8dd1-4292-9806-4d20186bb524",
         "metadata": {},
         "outputs": [],
         "source": [
            "def validation_loop(model, dataset, epoch):\n",
            "    print(f\"\\nValidating...\", end=\"\")\n",
            "    # Validation Evaluation\n",
            "    model = model.eval()  # Set the model to evaluation mode\n",
            "    \n",
            "    total_val_loss = 0.0\n",
            "    # total_val_mcrmse = 0.0\n",
            "    \n",
            "    val_batches = dataset.get_batch('val')\n",
            "    \n",
            "    num_val_batches = len(dataset.val_data) // BATCH_SIZE\n",
            "    with torch.no_grad():  # Disable gradient computations\n",
            "        for i, val_batch in enumerate(val_batches):\n",
            "            student_id = val_batch['student_id']\n",
            "            prompt_id = val_batch['prompt_id']\n",
            "            t_q_a_embeddings = val_batch['t_q_a_embeddings']\n",
            "            embeddings_text = val_batch['embeddings_text']\n",
            "            content = val_batch['content']\n",
            "            wording = val_batch['wording']\n",
            "            normalized_lexical_density = val_batch['normalized_lexical_density']\n",
            "            normalized_spell_checker = val_batch['normalized_spell_checker']\n",
            "            normalized_tf_idf_question_score = val_batch['normalized_tf_idf_question_score']\n",
            "            normalized_avg_word_length = val_batch['normalized_avg_word_length']\n",
            "            normalized_smog_index = val_batch['normalized_smog_index']\n",
            "            normalized_coleman_liau_index = val_batch['normalized_coleman_liau_index']\n",
            "            normalized_flesch_reading_ease = val_batch['normalized_flesch_reading_ease']\n",
            "\n",
            "            # Create input\n",
            "            val_input_data = torch.cat(\n",
            "                (\n",
            "                    embeddings_text,\n",
            "                    embeddings_question,\n",
            "                    embeddings_answer\n",
            "                ), dim=1).to(device)\n",
            "            val_targets = torch.stack((content, wording), dim=1).to(device)\n",
            "            \n",
            "            features = (normalized_lexical_density, \\\n",
            "                        normalized_spell_checker, \\\n",
            "                        normalized_tf_idf_question_score, \\\n",
            "                        normalized_avg_word_length, \\\n",
            "                        normalized_smog_index, \\\n",
            "                        normalized_coleman_liau_index, \\\n",
            "                        normalized_flesch_reading_ease \\\n",
            "                       )\n",
            "            # Forward pass\n",
            "            val_outputs = model(embeddings_text, t_q_a_embeddings, features)\n",
            "\n",
            "            # Compute loss and MCRMSE\n",
            "            val_loss = criterion(val_targets, val_outputs)\n",
            "            # val_mcrmse = MCRMSE(val_targets, val_outputs)\n",
            "\n",
            "            total_val_loss += val_loss.item()\n",
            "            # total_val_mcrmse += val_mcrmse.item()\n",
            "\n",
            "    avg_val_loss = total_val_loss / num_val_batches\n",
            "    # avg_val_mcrmse = total_val_mcrmse / num_val_batches\n",
            "\n",
            "    print(f\"\\rValidation Loss after Epoch {epoch + 1}: {avg_val_loss}\\n\")\n",
            "    # print(f\"\\rValidation Loss after Epoch {epoch + 1}: {avg_val_loss}, Avg MCRMSE: {avg_val_mcrmse}\\n\")\n",
            "    \n",
            "    # return avg_val_loss, avg_val_mcrmse\n",
            "    return avg_val_loss"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "id": "892f78e8-72a3-48ab-8deb-d3443311b6e2",
         "metadata": {
            "scrolled": true
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch [1/100], Batch [238/238], Loss: 0.25973179936408997, MCRMSE: 0.31720280647277834\n",
                  "Validation Loss after Epoch 1: 0.2682429701089859, Avg MCRMSE: 0.3388161431934874\n",
                  "\n",
                  "Epoch [2/100], Batch [238/238], Loss: 0.25248727202415466, MCRMSE: 0.31985861063003545\n",
                  "Validation Loss after Epoch 2: 0.26209523844516885, Avg MCRMSE: 0.33074341865919404\n",
                  "\n",
                  "Epoch [3/100], Batch [238/238], Loss: 0.2335994690656662, MCRMSE: 0.307933896780014044\n",
                  "Validation Loss after Epoch 3: 0.2536515207108805, Avg MCRMSE: 0.3199382861286907\n",
                  "\n",
                  "Epoch [4/100], Batch [238/238], Loss: 0.18511031568050385, MCRMSE: 0.22136232256889343\n",
                  "Validation Loss after Epoch 4: 0.24474942229561886, Avg MCRMSE: 0.3074447984917689\n",
                  "\n",
                  "Epoch [5/100], Batch [238/238], Loss: 0.2413213551044464, MCRMSE: 0.303460240364074742\n",
                  "Validation Loss after Epoch 5: 0.23173163351366075, Avg MCRMSE: 0.2894761764397055\n",
                  "\n",
                  "Epoch [6/100], Batch [238/238], Loss: 0.2354806512594223, MCRMSE: 0.285915583372116166\n",
                  "Validation Loss after Epoch 6: 0.22078117349390255, Avg MCRMSE: 0.27543420736062324\n",
                  "\n",
                  "Epoch [7/100], Batch [238/238], Loss: 0.1535780429840088, MCRMSE: 0.199800625443458564\n",
                  "Validation Loss after Epoch 7: 0.20874658782603378, Avg MCRMSE: 0.2606907979411594\n",
                  "\n",
                  "Epoch [8/100], Batch [238/238], Loss: 0.20034341514110565, MCRMSE: 0.26415520906448364\n",
                  "Validation Loss after Epoch 8: 0.2041558363174988, Avg MCRMSE: 0.2543964194039167\n",
                  "\n",
                  "Epoch [9/100], Batch [238/238], Loss: 0.18037645518779755, MCRMSE: 0.21787530183792114\n",
                  "Validation Loss after Epoch 9: 0.1986595094203949, Avg MCRMSE: 0.24840598970146502\n",
                  "\n",
                  "Epoch [10/100], Batch [170/238], Loss: 0.21267983317375183, MCRMSE: 0.27100431919097913"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n",
                  "KeyboardInterrupt\n",
                  "\n"
               ]
            }
         ],
         "source": [
            "# Early stopping parameters\n",
            "patience = 5  # Number of epochs with no improvement after which training will be stopped\n",
            "counter = 0  # To count number of epochs with no improvement\n",
            "best_val_loss = None  # To keep track of best validation loss\n",
            "best_model_state = None  # To store best model's state\n",
            "\n",
            "train_losses = []\n",
            "# train_mcrmse = []\n",
            "val_losses = []\n",
            "# val_mcrmse = []\n",
            "\n",
            "for epoch in range(EPOCHS):\n",
            "    # training loop\n",
            "    model, epoch_train_loss = training_loop(model, dataset, epoch)\n",
            "    train_losses.append(epoch_train_loss)\n",
            "    # train_mcrmse.append(epoch_train_mcrmse)\n",
            "    \n",
            "    # validation loop\n",
            "    epoch_val_loss = validation_loop(model, dataset, epoch)\n",
            "    val_losses.append(epoch_val_loss)\n",
            "    # val_mcrmse.append(epoch_val_mcrmse)\n",
            "\n",
            "    # Check if this epoch's validation loss is the best we've seen so far.\n",
            "    if best_val_loss is None or epoch_val_loss < best_val_loss:\n",
            "        best_val_loss = epoch_val_loss\n",
            "        best_model_state = copy.deepcopy(model.state_dict())  # Save best model\n",
            "        counter = 0  # Reset counter\n",
            "    else:\n",
            "        counter += 1  # Increment counter as no improvement in validation loss\n",
            "\n",
            "    # If we've had patience number of epochs without improvement, stop training\n",
            "    if counter >= patience:\n",
            "        print(f\"Early stopping on epoch {epoch}. Best epoch was {epoch - counter} with val loss: {best_val_loss:.4f}.\")\n",
            "        break\n",
            "\n",
            "# Load best model weights\n",
            "model.load_state_dict(best_model_state)\n",
            "torch.save(model.state_dict(), './out/best_model.pt')  # Save the best model to disk\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "62f186fe-aa77-4f32-9332-b46a53d6407b",
         "metadata": {},
         "source": [
            "### Loss visualization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5ab4c6a2-d3e5-474d-9a69-b60e59513a6d",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_graphs(train_losses, val_losses):\n",
            "    # Monokai color palette\n",
            "    colors = ['#F92672', '#A6E22E', '#66D9EF', '#FD971F']\n",
            "    \n",
            "    # Set the background color and grid color\n",
            "    sns.set_style(\"darkgrid\", {\n",
            "        \"axes.facecolor\": \".1\",  # Dark background\n",
            "        \"grid.color\": \".15\",  # Slightly grayish grid lines\n",
            "        \"axes.labelcolor\": \"white\",\n",
            "        \"xtick.color\": \"white\",\n",
            "        \"ytick.color\": \"white\"\n",
            "    })\n",
            "\n",
            "    epochs = range(1, len(train_losses) + 1)\n",
            "\n",
            "    # Plotting the losses\n",
            "    plt.figure(figsize=(12, 6))\n",
            "\n",
            "    # Set entire background color\n",
            "    fig = plt.gcf()\n",
            "    fig.patch.set_facecolor('.1')  # Color for the whole backgroun\n",
            "\n",
            "    plt.subplot(1, 2, 1)\n",
            "    sns.lineplot(x=epochs, y=train_losses, label='Train Loss', marker='o', color=colors[0])\n",
            "    sns.lineplot(x=epochs, y=val_losses, label='Validation Loss', marker='o', color=colors[1])\n",
            "    plt.title('Training and Validation Loss', color='white')\n",
            "    plt.xlabel('Epochs')\n",
            "    plt.ylabel('Loss')\n",
            "    legend = plt.legend()\n",
            "    for text in legend.get_texts():\n",
            "        text.set_color(\"white\")  # Set the legend text color to white\n",
            "\n",
            "    # Plotting the MCRMSE\n",
            "    # plt.subplot(1, 2, 2)\n",
            "    # sns.lineplot(x=epochs, y=train_mcrmse, label='Train MCRMSE', marker='o', color=colors[2])\n",
            "    # sns.lineplot(x=epochs, y=val_mcrmse, label='Validation MCRMSE', marker='o', color=colors[3])\n",
            "    # plt.title('Training and Validation MCRMSE', color='white')\n",
            "    # plt.xlabel('Epochs')\n",
            "    # plt.ylabel('MCRMSE')\n",
            "    # legend = plt.legend()\n",
            "    # for text in legend.get_texts():\n",
            "    #     text.set_color(\"white\")  # Set the legend text color to white\n",
            "\n",
            "    plt.tight_layout()\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9d2a845c-f61e-4ae4-9a69-58b0c85f6d73",
         "metadata": {},
         "outputs": [],
         "source": [
            "# After training, call the function to plot\n",
            "plot_graphs(train_losses, val_losses)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b28171c7-d418-404a-a7e7-cfb3567c7c12",
         "metadata": {},
         "source": [
            "## Saving torch script"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "6a58131d-0d65-4e15-bd16-c67008f19d80",
         "metadata": {},
         "outputs": [],
         "source": [
            "model.load_state_dict(torch.load('./out/best_model.pt'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2a21393b-2e29-436e-bc9e-bc93f32469cc",
         "metadata": {},
         "outputs": [],
         "source": [
            "exemple_batches = dataset.get_batch('train')\n",
            "ex_batch = next(exemple_batches)\n",
            "t_q_a_embeddings = ex_batch['t_q_a_embeddings']\n",
            "embeddings_text = ex_batch['embeddings_text']\n",
            "embeddings_answer = ex_batch['text']\n",
            "content = ex_batch['content']\n",
            "wording = ex_batch['wording']\n",
            "normalized_lexical_density = ex_batch['normalized_lexical_density']\n",
            "normalized_spell_checker = ex_batch['normalized_spell_checker']\n",
            "normalized_tf_idf_question_score = ex_batch['normalized_tf_idf_question_score']\n",
            "normalized_avg_word_length = ex_batch['normalized_avg_word_length']\n",
            "normalized_smog_index = ex_batch['normalized_smog_index']\n",
            "normalized_coleman_liau_index = ex_batch['normalized_coleman_liau_index']\n",
            "normalized_flesch_reading_ease = ex_batch['normalized_flesch_reading_ease']\n",
            "\n",
            "# Create input\n",
            "input_data = torch.cat(\n",
            "    (\n",
            "        embeddings_text,\n",
            "        embeddings_question,\n",
            "        embeddings_answer\n",
            "    ), dim=1).to('cpu')\n",
            "\n",
            "features = (normalized_lexical_density.to('cpu'), \\\n",
            "            normalized_spell_checker.to('cpu'), \\\n",
            "            normalized_tf_idf_question_score.to('cpu'), \\\n",
            "            normalized_avg_word_length.to('cpu'), \\\n",
            "            normalized_smog_index.to('cpu'), \\\n",
            "            normalized_coleman_liau_index.to('cpu'), \\\n",
            "            normalized_flesch_reading_ease.to('cpu') \\\n",
            "           )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "72f85c4d-47fb-42d5-8b08-e90af1199874",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Trace the model\n",
            "traced_model = torch.jit.trace(model.to('cpu'), (embeddings_text.to('cpu'), t_q_a_embeddings.to('cpu'), features))\n",
            "# Save the traced model\n",
            "traced_model.save(\"./out/best_model_script.pt\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7860f40b-e9c7-4f20-9c9f-71ca695f20b7",
         "metadata": {},
         "outputs": [],
         "source": [
            "import math"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "70ad3e0e-5421-4bf2-9b25-6a77b4c40f33",
         "metadata": {},
         "outputs": [],
         "source": [
            "def t_round(x, decimals = 3):\n",
            "    multiplicator = 10**decimals\n",
            "    return torch.round(x * 1000) / 1000"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "8782aac0-bd1d-433b-b849-f4b784bb41ba",
         "metadata": {},
         "outputs": [],
         "source": [
            "tensor1, tensor2 = model(embeddings_text.to('cpu'), t_q_a_embeddings.to('cpu'), features), torch.stack((normalized_content, normalized_wording), dim=1)\n",
            "\n",
            "\n",
            "for (col1_tensor1, col2_tensor1), (col1_tensor2, col2_tensor2) in zip(tensor1, tensor2):\n",
            "    print(f\"[{col1_tensor1:>6.3f} => {col1_tensor2:>6.3f} = {col1_tensor2-col1_tensor1:>6.3f}] \\t | \\t [{col2_tensor1:>6.3f} => {col2_tensor2:>6.3f} = {col2_tensor2 - col2_tensor1:>6.3f}]\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "id": "a30afdbd-630e-4182-97e0-9e0174dbe3b7",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [-0.418 => -0.234 =  0.184] \t | \t [-0.422 => -0.390 =  0.032]\n",
            "# [-0.261 => -0.114 =  0.147] \t | \t [-0.298 => -0.193 =  0.105]\n",
            "# [-0.543 => -0.621 = -0.078] \t | \t [-0.391 => -0.668 = -0.277]\n",
            "# [-0.205 => -0.204 =  0.001] \t | \t [-0.242 => -0.573 = -0.331]\n",
            "# [-0.383 => -0.285 =  0.098] \t | \t [-0.383 => -0.318 =  0.065]\n",
            "# [ 0.008 =>  0.095 =  0.087] \t | \t [-0.194 => -0.167 =  0.027]\n",
            "# [-0.041 =>  0.257 =  0.298] \t | \t [-0.188 => -0.151 =  0.037]\n",
            "# [-0.130 => -0.187 = -0.057] \t | \t [-0.060 =>  0.044 =  0.104]\n",
            "# [-0.370 => -0.464 = -0.094] \t | \t [-0.374 => -0.640 = -0.266]\n",
            "# [-0.434 =>  0.341 =  0.775] \t | \t [-0.396 => -0.182 =  0.214]\n",
            "# [-0.757 => -0.849 = -0.092] \t | \t [-0.694 => -0.820 = -0.126]\n",
            "# [ 0.091 =>  0.250 =  0.159] \t | \t [ 0.057 =>  0.265 =  0.208]"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "f58a7665-b682-436b-a62e-a0365521f75a",
         "metadata": {},
         "source": [
            "## Load the Traced Model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "113464e4-6ea3-4ce7-9fd0-2b4074602278",
         "metadata": {},
         "outputs": [],
         "source": [
            "loaded_model = torch.jit.load(\"./out/best_model_script.pt\").to(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c45cdfba-440d-4de0-ac11-22382d876f89",
         "metadata": {},
         "outputs": [],
         "source": [
            "features = (normalized_lexical_density.to(device), \\\n",
            "            normalized_spell_checker.to(device), \\\n",
            "            normalized_tf_idf_question_score.to(device), \\\n",
            "            normalized_avg_word_length.to(device), \\\n",
            "            normalized_smog_index.to(device), \\\n",
            "            normalized_coleman_liau_index.to(device), \\\n",
            "            normalized_flesch_reading_ease.to(device) \\\n",
            "           )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c66825f1-b925-463f-bec3-f5a3b20646b9",
         "metadata": {},
         "outputs": [],
         "source": [
            "loaded_model(embeddings_text.to(device), t_q_a_embeddings.to(device), features)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "id": "2e2af4b4-9728-46ab-974c-cc7ec23224bb",
         "metadata": {},
         "outputs": [],
         "source": [
            "def test_model():\n",
            "    test_batches = dataset.get_batch('test')\n",
            "    list_mcrmse = []\n",
            "    list_outputs = []\n",
            "    list_targets = []\n",
            "    for index, test_batch in enumerate(test_batches):\n",
            "        print(f\"\\r [{index}/{len(dataset.test_data) // BATCH_SIZE}]\", end=\"\")\n",
            "        \n",
            "        embeddings_question = test_batch['embeddings_question']\n",
            "        embeddings_text = test_batch['embeddings_text']\n",
            "        embeddings_answer = test_batch['text']\n",
            "        content = test_batch['content']\n",
            "        wording = test_batch['wording']\n",
            "        normalized_lexical_density = test_batch['normalized_lexical_density']\n",
            "        normalized_spell_checker = test_batch['normalized_spell_checker']\n",
            "        normalized_tf_idf_question_score = test_batch['normalized_tf_idf_question_score']\n",
            "        normalized_avg_word_length = test_batch['normalized_avg_word_length']\n",
            "        normalized_smog_index = test_batch['normalized_smog_index']\n",
            "        normalized_coleman_liau_index = test_batch['normalized_coleman_liau_index']\n",
            "        normalized_flesch_reading_ease = test_batch['normalized_flesch_reading_ease']\n",
            "\n",
            "        # Create input\n",
            "        input_data = torch.cat(\n",
            "            (\n",
            "                embeddings_text,\n",
            "                embeddings_question,\n",
            "                embeddings_answer\n",
            "            ), dim=1).to('cpu')\n",
            "        \n",
            "        features = (normalized_lexical_density.to('cpu'), \\\n",
            "                    normalized_spell_checker.to('cpu'), \\\n",
            "                    normalized_tf_idf_question_score.to('cpu'), \\\n",
            "                    normalized_avg_word_length.to('cpu'), \\\n",
            "                    normalized_smog_index.to('cpu'), \\\n",
            "                    normalized_coleman_liau_index.to('cpu'), \\\n",
            "                    normalized_flesch_reading_ease.to('cpu') \\\n",
            "                   )\n",
            "        outputs = loaded_model(input_data, features)\n",
            "        targets = torch.stack(\n",
            "            (\n",
            "                content,\n",
            "                wording\n",
            "            ), dim=1).to('cpu')\n",
            "        \n",
            "        val_mcrmse = MCRMSE(targets, outputs)\n",
            "        list_mcrmse.append(val_mcrmse.item())\n",
            "        list_outputs += outputs.detach().cpu().numpy().tolist()\n",
            "        list_targets += targets.detach().cpu().numpy().tolist()\n",
            "    print()\n",
            "    return list_mcrmse, list_outputs, list_targets\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "id": "36518bbf-1146-482f-a148-3ee4f626860c",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  " [35/35]\n"
               ]
            }
         ],
         "source": [
            "list_mcrmse, list_pred, list_targets = test_model()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "id": "a6b145c5-1765-41d0-aa6a-38a0c34a8a03",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(860, 2, 860, 2)"
                  ]
               },
               "execution_count": 32,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(list_pred), len(list_pred[0]), len(list_targets), len(list_targets[0])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "id": "df9b0f83-950b-4fb2-97cb-04c1fdbaadd1",
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "def cal_accu(pred, real):\n",
            "    predicted_labels = torch.argmax(pred, dim=1)\n",
            "\n",
            "    # Get the true labels\n",
            "    true_labels = torch.argmax(real, dim=1)\n",
            "    \n",
            "    # Calculate the number of correct predictions\n",
            "    correct = (predicted_labels == true_labels).sum().item()\n",
            "    \n",
            "    # Calculate accuracy\n",
            "    accuracy = correct / pred.size(0) * 100  # pred.size(0) gives the batch size\n",
            "    \n",
            "    print(f\"Accuracy: {accuracy}%\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "id": "b56ad30f-6e7f-4f70-b3a6-ec631fd12831",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Accuracy: 65.34883720930232%\n"
               ]
            }
         ],
         "source": [
            "cal_accu(torch.tensor(list_pred), torch.tensor(list_targets))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b2b1ca51-515b-483c-ae92-3ac33f2f54a8",
         "metadata": {},
         "source": [
            "Accuracy: 69.65116279069767%"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "id": "ae610d03-9a00-4b4f-87b6-2de99bb9ef8b",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.6116314522094197"
                  ]
               },
               "execution_count": 35,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import math\n",
            "sum(list_mcrmse) / len(list_mcrmse)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "4fe2b692-f8dd-4f68-aa6a-4b56c9781cce",
         "metadata": {},
         "source": [
            "0.1883068767686685"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "id": "83e6baac-3699-4602-ac14-78a704a8a08e",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "plt.ioff()  # Turn off interactive mode\n",
            "plt.plot(list_mcrmse)\n",
            "\n",
            "# Setting axes labels and title\n",
            "plt.xlabel('X-axis Label')\n",
            "plt.ylabel('Y-axis Label')\n",
            "plt.title('Plot Title')\n",
            "# Setting ticks explicitly\n",
            "plt.tick_params(axis='both', labelcolor='black', labelsize='medium')\n",
            "\n",
            "plt.draw()  # Explicitly redraw the figure\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 37,
         "id": "c2099e47-09b4-4fae-8672-c477d5b5bd12",
         "metadata": {},
         "outputs": [
            {
               "ename": "AssertionError",
               "evalue": "",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
                  "\u001b[0;31mAssertionError\u001b[0m: "
               ]
            }
         ],
         "source": [
            "assert 'a' == 'b'"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "09318c69-ee9d-4cf4-8dae-14b4a193b034",
         "metadata": {},
         "source": [
            "## export sentence transformer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "311dc54c-f855-4d24-9337-58e1ad00c931",
         "metadata": {},
         "outputs": [],
         "source": [
            "from transformers import AutoTokenizer, AutoModel\n",
            "import torch\n",
            "import torch.nn.functional as F"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c3ffcf50-3449-4236-aec2-d621488df8ab",
         "metadata": {},
         "outputs": [],
         "source": [
            "#Mean Pooling - Take attention mask into account for correct averaging\n",
            "def mean_pooling(model_output, attention_mask):\n",
            "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
            "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
            "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fb5e1164-4f09-4d2b-9c1e-b4a496d4778c",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Sentences we want sentence embeddings for\n",
            "sentences = ['This is an example sentence', 'Each sentence is converted']"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1cfffd3d-3a89-49e3-a3fc-71ddc4c2030a",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Load model from HuggingFace Hub\n",
            "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
            "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5317046a-e6ea-414b-9436-8040813ccd1d",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Tokenize sentences\n",
            "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "41505048-de86-4300-a07d-1acea9a98eb5",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Compute token embeddings\n",
            "with torch.no_grad():\n",
            "    model_output = model(**encoded_input)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1a18a32a-1134-41ff-b4ae-0bda5befa2c7",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Perform pooling\n",
            "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5ea3d8c6-6c0b-4bb4-b196-20e39d41427e",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Normalize embeddings\n",
            "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5609c6ba-b4f7-4e44-b4e1-4b48c0b6b1a7",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(\"Sentence embeddings:\")\n",
            "print(sentence_embeddings.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "a13b2cc3-98b2-4571-9ac4-8f2b12b5aa24",
         "metadata": {},
         "outputs": [],
         "source": [
            "class SentenceTransformer(torch.nn.Module):\n",
            "    def __init__(self, repo):\n",
            "        super(SentenceTransformer, self).__init__()\n",
            "        self.tokenizer = AutoTokenizer.from_pretrained(repo)\n",
            "        self.model = AutoModel.from_pretrained(repo)\n",
            "\n",
            "    #Mean Pooling - Take attention mask into account for correct averaging\n",
            "    def _mean_pooling(self, model_output, attention_mask):\n",
            "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
            "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
            "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
            "\n",
            "    def encode(self, sentences):\n",
            "        # Tokenize sentences\n",
            "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
            "        # Compute token embeddings\n",
            "        with torch.no_grad():\n",
            "            model_output = self.model(**encoded_input)\n",
            "        # Perform pooling\n",
            "        sentence_embeddings = self._mean_pooling(model_output, encoded_input['attention_mask'])\n",
            "        # Normalize embeddings\n",
            "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
            "        return sentence_embeddings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b2e0c373-0bef-421d-8f16-4b6896a26f73",
         "metadata": {},
         "outputs": [],
         "source": [
            "sentence_transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "95742369-6376-4f15-b761-1c0084706f63",
         "metadata": {},
         "outputs": [],
         "source": [
            "embeddings = sentence_transformer.encode(sentences)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "6cffbcd0-68fb-4345-9cbc-2b0783c7f9aa",
         "metadata": {},
         "outputs": [],
         "source": [
            "embeddings.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d9aeb6dc-c24e-49ac-a4da-0d4b46e458f3",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.5"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}