{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "0a14353b-46a1-4c60-9ee7-080174af9aa7",
         "metadata": {},
         "source": [
            "# Sentence Transformer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 72,
         "id": "9c8f10e2-148a-44e1-8cf6-748a75601885",
         "metadata": {},
         "outputs": [],
         "source": [
            "import copy\n",
            "import torch\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from sentence_transformers import SentenceTransformer\n",
            "from transformers import DebertaV2Tokenizer, DebertaV2Model\n",
            "\n",
            "from torch.utils.data import Dataset, DataLoader\n",
            "from datasets import load_from_disk"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "9e45dabc-8015-4143-b354-2198a598f09b",
         "metadata": {},
         "outputs": [],
         "source": [
            "import re\n",
            "import string"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "27656d7a-a0cf-4693-a0b7-c046685ed806",
         "metadata": {},
         "outputs": [],
         "source": [
            "import textstat\n",
            "from spellchecker import SpellChecker\n",
            "from lexical_density import lexical_density as Lexical_Density\n",
            "from TF_IDF import calc_tf_idf\n",
            "from Add_Periods import Add_Periods\n",
            "from avg_word_sentence_length import average_word_length, average_sentence_length\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "f77e5e25-bb6f-453b-86b5-addc6cc72a7a",
         "metadata": {},
         "source": [
            "## GPU"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "d06b53bf-a6eb-4fce-af1d-814fc0a022ea",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Sat Sep 30 16:06:11 2023       \n",
                  "+---------------------------------------------------------------------------------------+\n",
                  "| NVIDIA-SMI 536.99                 Driver Version: 536.99       CUDA Version: 12.2     |\n",
                  "|-----------------------------------------+----------------------+----------------------+\n",
                  "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
                  "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
                  "|                                         |                      |               MIG M. |\n",
                  "|=========================================+======================+======================|\n",
                  "|   0  NVIDIA GeForce GTX 1070      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
                  "| 28%   39C    P8              11W / 151W |    701MiB /  8192MiB |      1%      Default |\n",
                  "|                                         |                      |                  N/A |\n",
                  "+-----------------------------------------+----------------------+----------------------+\n",
                  "                                                                                         \n",
                  "+---------------------------------------------------------------------------------------+\n",
                  "| Processes:                                                                            |\n",
                  "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
                  "|        ID   ID                                                             Usage      |\n",
                  "|=======================================================================================|\n",
                  "|    0   N/A  N/A      2472    C+G   ...Brave-Browser\\Application\\brave.exe    N/A      |\n",
                  "|    0   N/A  N/A      5720    C+G   ...ejd91yc\\AdobeNotificationClient.exe    N/A      |\n",
                  "|    0   N/A  N/A      7964    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
                  "|    0   N/A  N/A     10252    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
                  "|    0   N/A  N/A     14396    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
                  "|    0   N/A  N/A     15452    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
                  "|    0   N/A  N/A     16592    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
                  "|    0   N/A  N/A     18416    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n",
                  "|    0   N/A  N/A     19580    C+G   ...Data\\Local\\Programs\\Blitz\\Blitz.exe    N/A      |\n",
                  "|    0   N/A  N/A     23144    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
                  "|    0   N/A  N/A     24372    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
                  "|    0   N/A  N/A     27180    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
                  "|    0   N/A  N/A     27656    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
                  "|    0   N/A  N/A     30980    C+G   ...7.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
                  "|    0   N/A  N/A     30984    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
                  "+---------------------------------------------------------------------------------------+\n"
               ]
            }
         ],
         "source": [
            "!nvidia-smi"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "28da5a7c-b1ca-4bd3-b7c9-77a6137bb795",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "device(type='cpu')"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Check if CUDA is available, else use CPU\n",
            "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
            "device"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "18bd7321-ba11-4a3a-b3f4-70ec0c7f33b3",
         "metadata": {},
         "source": [
            "## Utils"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "742575e5-761a-4eee-8cae-e0bee0b4803b",
         "metadata": {},
         "outputs": [],
         "source": [
            "def spell_checker_score(text, debug = False):\n",
            "    def remove_punctuation(st):\n",
            "        return re.sub(f\"[{re.escape(string.punctuation)}]\", '', st)\n",
            "    \n",
            "    spell = SpellChecker()\n",
            "    misspelled = spell.unknown(remove_punctuation(text).split())\n",
            "\n",
            "    if debug:\n",
            "        for word in misspelled:\n",
            "            # Get the one `most likely` answer\n",
            "            print(f\"{word} => {spell.correction(word)}\")\n",
            "        \n",
            "        print(f\"misspelled: {len(misspelled)}\")\n",
            "    return len(misspelled)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 73,
         "id": "b83692bd-f88a-4d3c-8994-79dbf2c4bfa6",
         "metadata": {},
         "outputs": [],
         "source": [
            "class SentenceTransformer(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(SentenceTransformer, self).__init__()\n",
            "        # Load the tokenizer and model\n",
            "        self.tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
            "        self.model = DebertaV2Model.from_pretrained('microsoft/deberta-v3-base')\n",
            "\n",
            "    def encode(self, sentences):\n",
            "        # Tokenize sentences\n",
            "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
            "        # Compute token embeddings\n",
            "        with torch.no_grad():\n",
            "            model_output = self.model(**encoded_input)\n",
            "            \n",
            "        # Only take the embeddings of the [CLS] token (or use the mean of the token embeddings if desired)\n",
            "        sentence_embeddings = model_output.last_hidden_state[:, 0, :]\n",
            "        \n",
            "        return sentence_embeddings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 74,
         "id": "b514473a-1693-45e7-a0f0-edc56398cedf",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
               ]
            }
         ],
         "source": [
            "deberta = SentenceTransformer()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 75,
         "id": "1622b6e4-c1b0-4ac2-8f69-ccbb8004feb2",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "tensor([[ 0.1804,  0.2592,  0.0357, -0.1198,  0.1036]])\n",
                  "tensor([[ 0.1804,  0.2592,  0.0357, -0.1198,  0.1036]])\n"
               ]
            }
         ],
         "source": [
            "\n",
            "# Example usage:\n",
            "text = \"Hugging Face is creating a tool that democratizes AI.\"\n",
            "embedding = get_embedding(text)\n",
            "print(embedding[:, :5])\n",
            "print(deberta.encode(text)[:, :5])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 78,
         "id": "66a6ae3c-0e78-409a-ae07-b575f344dc7e",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(14,\n",
                     " {'input_ids': [1, 88419, 510, 8834, 269, 1512, 266, 1637, 272, 92146, 268, 5536, 260, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
                  ]
               },
               "execution_count": 78,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(deberta.tokenizer(text)['input_ids']), deberta.tokenizer(text)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a1fd958f-82f1-4f6b-9a00-97c41e225c30",
         "metadata": {},
         "source": [
            "## Generate dataset and batch"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fd6d7c30-5744-4c0d-824d-dcc667e50a9f",
         "metadata": {},
         "outputs": [],
         "source": [
            "class PromptDataset(Dataset):\n",
            "\n",
            "    def __init__(self, dataset, device):\n",
            "        self.dataset = dataset\n",
            "        self.device = device\n",
            "\n",
            "    def deserialize_array(self, binary_string, dtype, shape):\n",
            "        return np.frombuffer(binary_string, dtype=dtype).reshape(shape)\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        data = self.dataset[index]\n",
            "        # retrieve values\n",
            "        student_id = data['student_id']\n",
            "        prompt_id = data['prompt_id']\n",
            "        embeddings_question = torch.tensor(self.deserialize_array(data['embeddings_question'], np.float32, (768,))).to(self.device)\n",
            "        embeddings_text = torch.tensor(self.deserialize_array(data['embeddings_text'], np.float32, (768,))).to(self.device)\n",
            "        text = torch.tensor(self.deserialize_array(data['text'], np.float32, (768,))).to(self.device)\n",
            "        content = torch.tensor(data['content']).to(self.device)\n",
            "        wording = torch.tensor(data['wording']).to(self.device)\n",
            "        normalized_lexical_density = torch.tensor(data['normalized_lexical_density']).unsqueeze(0).to(self.device)\n",
            "        normalized_spell_checker = torch.tensor(data['normalized_spell_checker']).unsqueeze(0).to(self.device)\n",
            "        normalized_tf_idf_question_score = torch.tensor(data['normalized_tf_idf_question_score']).unsqueeze(0).to(self.device)\n",
            "        normalized_avg_word_length = torch.tensor(data['normalized_avg_word_length']).unsqueeze(0).to(self.device)\n",
            "        normalized_smog_index = torch.tensor(data['normalized_smog_index']).unsqueeze(0).to(self.device)\n",
            "        normalized_coleman_liau_index = torch.tensor(data['normalized_coleman_liau_index']).unsqueeze(0).to(self.device)\n",
            "        normalized_flesch_reading_ease = torch.tensor(data['normalized_flesch_reading_ease']).unsqueeze(0).to(self.device)\n",
            "        \n",
            "        return {\n",
            "            'student_id': student_id,\n",
            "            'prompt_id': prompt_id,\n",
            "            'embeddings_question': embeddings_question,\n",
            "            'embeddings_text': embeddings_text,\n",
            "            'text': text,\n",
            "            'content': content,\n",
            "            'wording': wording,\n",
            "            'normalized_lexical_density': normalized_lexical_density,\n",
            "            'normalized_spell_checker': normalized_spell_checker,\n",
            "            'normalized_tf_idf_question_score': normalized_tf_idf_question_score,\n",
            "            'normalized_avg_word_length': normalized_avg_word_length,\n",
            "            'normalized_smog_index': normalized_smog_index,\n",
            "            'normalized_coleman_liau_index': normalized_coleman_liau_index,\n",
            "            'normalized_flesch_reading_ease': normalized_flesch_reading_ease,\n",
            "        }\n",
            "\n",
            "    def __len__(self) -> int :\n",
            "        return self.dataset.num_rows"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "843e316c-df6c-485f-8561-6f890c556f87",
         "metadata": {},
         "outputs": [],
         "source": [
            "class DataLoaderFactory():\n",
            "\n",
            "    def __init__(self, path:str = './data/hugging_face', batch_size = 12, device = 'cpu'):\n",
            "        self.batch_size = batch_size\n",
            "        self.dataset = load_from_disk(path, keep_in_memory=True)\n",
            "        self.device = device\n",
            "\n",
            "        print(\"1. Loading dataset: ...\", end=\"\")\n",
            "        dataset = load_from_disk(path, keep_in_memory=True)\n",
            "        print(\"\\r1. Loading dataset: done ✔️\")\n",
            "\n",
            "        print(\"2. Split datasets: ...\", end=\"\")\n",
            "        train_validation_splits = self.dataset['train'].train_test_split(test_size=0.2)\n",
            "        print(\"\\r2. Preprocess datasets: done ✔️\")\n",
            "\n",
            "        print(\"3. Split datasets: ...\", end=\"\")\n",
            "        self.train_data = PromptDataset(train_validation_splits['train'], self.device)\n",
            "        self.val_data = PromptDataset(train_validation_splits['test'], self.device)\n",
            "        print(\"\\r3. Split datasets: done ✔️\")\n",
            "\n",
            "        self.dataloader_train = DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n",
            "        self.dataloader_val = DataLoader(self.val_data, batch_size=batch_size, shuffle=True)\n",
            "    \n",
            "    \n",
            "    def __len__(self) -> int :\n",
            "        print(\"\\033[95m\\033[1m\\033[4mNumber of data by datasets splits\\033[0m\")\n",
            "        print(f\"Train\\t\\t: {len(self.train_data)}\\t-> {len(self.train_data)/self.batch_size}\")\n",
            "        print(f\"Validation\\t: {len(self.val_data)}\\t\\t-> {len(self.val_data)/self.batch_size}\")\n",
            "        total = len(self.train_data) + len(self.val_data)\n",
            "        print(f\"Total\\t\\t: {total}\")\n",
            "        return total\n",
            "\n",
            "    def get_batch(self, split):\n",
            "        # choose the correct dataloader\n",
            "        if split == 'train':\n",
            "            dataloader = self.dataloader_train\n",
            "        else:\n",
            "            dataloader = self.dataloader_val\n",
            "\n",
            "        for batch in dataloader:\n",
            "            # Move tensors to device\n",
            "            batch_on_device = {k: v for k, v in batch.items()}\n",
            "            yield batch_on_device"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d18f4fc8-1830-4fab-ae74-d12fb945f374",
         "metadata": {},
         "source": [
            "### Load the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f67182de-ccb8-4f77-87e0-5c88be245435",
         "metadata": {},
         "outputs": [],
         "source": [
            "dataset = DataLoaderFactory(device=device)\n",
            "len(dataset)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1c5e512f-1fad-4c54-80c5-c0500a25f086",
         "metadata": {},
         "source": [
            "### Testing the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fded6cee-24b5-4d28-a3df-a857fd1336c7",
         "metadata": {},
         "outputs": [],
         "source": [
            "batch = dataset.get_batch('train')\n",
            "nb = next(batch)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1ae8f919-4ba2-46be-be03-d47b248ddd70",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(f\"{'student_id:':<25}{len(nb['student_id'])}\")\n",
            "print(f\"{'prompt_id:':<25}{len(nb['prompt_id'])}\")\n",
            "print(f\"{'embeddings_question:':<25}{nb['embeddings_question'].shape}\")\n",
            "print(f\"{'embeddings_text:':<25}{nb['embeddings_text'].shape}\")\n",
            "print(f\"{'text:':<25}{nb['text'].shape}\")\n",
            "print(f\"{'content:':<25}{nb['content'].shape}\")\n",
            "print(f\"{'wording:':<25}{nb['wording'].shape}\")\n",
            "print(f\"{'normalized_lexical_density:':<25}{nb['normalized_lexical_density'].shape}\")\n",
            "print(f\"{'normalized_spell_checker:':<25}{nb['normalized_spell_checker'].shape}\")\n",
            "print(f\"{'normalized_tf_idf_question_score:':<25}{nb['normalized_tf_idf_question_score'].shape}\")\n",
            "print(f\"{'normalized_avg_word_length:':<25}{nb['normalized_avg_word_length'].shape}\")\n",
            "print(f\"{'normalized_smog_index:':<25}{nb['normalized_smog_index'].shape}\")\n",
            "print(f\"{'normalized_coleman_liau_index:':<25}{nb['normalized_coleman_liau_index'].shape}\")\n",
            "print(f\"{'normalized_flesch_reading_ease:':<25}{nb['normalized_flesch_reading_ease'].shape}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "90125960-7f7e-48e8-a57b-1c3169e3de62",
         "metadata": {},
         "source": [
            "## Kaggle evaluation"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6b89aa4c-b050-4dd8-8f4b-070fe574653c",
         "metadata": {},
         "source": [
            "### Paths"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d66c94f7-c78a-4c41-9480-9bcc996d1998",
         "metadata": {},
         "outputs": [],
         "source": [
            "prompts_train_path = \"./data/prompts_train.csv\"\n",
            "prompts_test_path = \"./data/prompts_test.csv\"\n",
            "\n",
            "summaries_train_path = \"./data/summaries_train.csv\"\n",
            "summaries_test_path = \"./data/summaries_test.csv\"\n",
            "\n",
            "model_path = \"./out/best_model_script.pt\"\n",
            "\n",
            "submission_path = \"./out/submission.csv\""
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9afbd7cd-e0dc-434b-98d7-e433116855d4",
         "metadata": {},
         "source": [
            "### Loading Model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f86ed7ae-5764-402f-a29a-101ad1a83234",
         "metadata": {},
         "outputs": [],
         "source": [
            "exemple_batches = dataset.get_batch('train')\n",
            "ex_batch = next(exemple_batches)\n",
            "embeddings_question = ex_batch['embeddings_question']\n",
            "embeddings_text = ex_batch['embeddings_text']\n",
            "embeddings_answer = ex_batch['text']\n",
            "\n",
            "content = ex_batch['content']\n",
            "wording = ex_batch['wording']\n",
            "\n",
            "normalized_lexical_density = ex_batch['normalized_lexical_density']\n",
            "normalized_spell_checker = ex_batch['normalized_spell_checker']\n",
            "normalized_tf_idf_question_score = ex_batch['normalized_tf_idf_question_score']\n",
            "normalized_avg_word_length = ex_batch['normalized_avg_word_length']\n",
            "normalized_smog_index = ex_batch['normalized_smog_index']\n",
            "normalized_coleman_liau_index = ex_batch['normalized_coleman_liau_index']\n",
            "normalized_flesch_reading_ease = ex_batch['normalized_flesch_reading_ease']\n",
            "\n",
            "example_input_tensor = torch.cat(\n",
            "    (\n",
            "        embeddings_text,\n",
            "        embeddings_question,\n",
            "        embeddings_answer\n",
            "    ), dim=1)\n",
            "features = (normalized_lexical_density.to(device), \\\n",
            "            normalized_spell_checker.to(device), \\\n",
            "            normalized_tf_idf_question_score.to(device), \\\n",
            "            normalized_avg_word_length.to(device), \\\n",
            "            normalized_smog_index.to(device), \\\n",
            "            normalized_coleman_liau_index.to(device), \\\n",
            "            normalized_flesch_reading_ease.to(device) \\\n",
            "           )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "63bb8e39-f1a4-4eac-bcd3-7fc810699192",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([12, 768])\n",
                  "torch.Size([12, 1])\n",
                  "torch.Size([12, 1])\n",
                  "torch.Size([12, 1])\n",
                  "torch.Size([12, 1])\n",
                  "torch.Size([12, 1])\n",
                  "torch.Size([12, 1])\n",
                  "torch.Size([12, 1])\n"
               ]
            }
         ],
         "source": [
            "print(embeddings_answer.shape)\n",
            "for x in features:\n",
            "    print(x.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "id": "ce749a10-ac04-4447-abb3-de63a86b039d",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "RecursiveScriptModule(\n",
                     "  original_name=QA_Score_Model\n",
                     "  (fc_text_question_answer): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_lexical): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_spell): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_tfidf): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_avg_word_length): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_smog): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_coleman): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc_flesch): RecursiveScriptModule(original_name=Linear)\n",
                     "  (dropout): RecursiveScriptModule(original_name=Dropout)\n",
                     "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
                     "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
                     "  (out_content): RecursiveScriptModule(original_name=Linear)\n",
                     "  (out_wording): RecursiveScriptModule(original_name=Linear)\n",
                     ")"
                  ]
               },
               "execution_count": 15,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "loaded_model = torch.jit.load(model_path).to(device)\n",
            "loaded_model.eval()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5cdcb9db-726b-4cc6-adec-f961b958a5d3",
         "metadata": {},
         "outputs": [],
         "source": [
            "# loaded_model(example_input_tensor.to(device))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "id": "edd0aef4-bdaa-46ef-86ae-40f2b829cc82",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[-0.196 => -0.249 = -0.053] \t | \t [-0.497 =>  0.383 =  0.880]\n",
                  "[-0.589 => -0.457 =  0.132] \t | \t [ 0.015 => -0.043 = -0.058]\n",
                  "[ 0.318 =>  0.376 =  0.058] \t | \t [ 0.166 =>  0.464 =  0.297]\n",
                  "[ 0.415 =>  1.076 =  0.662] \t | \t [-0.062 =>  0.074 =  0.136]\n",
                  "[-0.678 => -0.564 =  0.114] \t | \t [-0.740 =>  0.544 =  1.284]\n",
                  "[-0.209 => -0.393 = -0.184] \t | \t [-0.129 =>  0.627 =  0.756]\n",
                  "[ 0.842 =>  1.268 =  0.426] \t | \t [ 0.392 =>  0.579 =  0.187]\n",
                  "[ 1.542 =>  1.782 =  0.240] \t | \t [ 1.032 =>  0.912 = -0.120]\n",
                  "[-0.936 => -1.264 = -0.328] \t | \t [-0.899 => -1.505 = -0.606]\n",
                  "[-0.993 => -0.794 =  0.199] \t | \t [-1.179 => -1.545 = -0.366]\n",
                  "[-0.517 => -0.564 = -0.046] \t | \t [-0.789 => -1.127 = -0.338]\n",
                  "[-0.323 => -0.993 = -0.671] \t | \t [ 0.336 => -0.367 = -0.703]\n"
               ]
            }
         ],
         "source": [
            "# tensor1, tensor2 = loaded_model(example_input_tensor.to(device)), torch.stack((content, wording), dim=1)\n",
            "tensor1, tensor2 = loaded_model(example_input_tensor.to('cpu'), features), torch.stack((content, wording), dim=1)\n",
            "\n",
            "for (col1_tensor1, col2_tensor1), (col1_tensor2, col2_tensor2) in zip(tensor1, tensor2):\n",
            "    print(f\"[{col1_tensor1:>6.3f} => {col1_tensor2:>6.3f} = {col1_tensor2-col1_tensor1:>6.3f}] \\t | \\t [{col2_tensor1:>6.3f} => {col2_tensor2:>6.3f} = {col2_tensor2 - col2_tensor1:>6.3f}]\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "575c3f66-776f-4fff-8491-ed02133ee807",
         "metadata": {},
         "source": [
            "### Load SentenceTransformer model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c4baffed-cbc7-4f13-bc26-e3334e4adb2a",
         "metadata": {},
         "outputs": [],
         "source": [
            "sentence_transformer_model = SentenceTransformer('all-mpnet-base-v2')"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "cf3d0706-e52f-4c64-bef2-1985c089a4b5",
         "metadata": {},
         "source": [
            "### Loading files"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "acb4a847-4cbe-4386-b4fc-202ddeec7d45",
         "metadata": {},
         "outputs": [],
         "source": [
            "prompts_train = pd.read_csv(prompts_train_path)\n",
            "prompts_test = pd.read_csv(prompts_test_path)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "661771f2-7416-45fb-923d-aa04ee72f7c6",
         "metadata": {},
         "outputs": [],
         "source": [
            "summaries_train = pd.read_csv(summaries_train_path)\n",
            "summaries_test = pd.read_csv(summaries_test_path)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "61a8adba-7a33-463b-ac55-65dfc0c6cbef",
         "metadata": {},
         "outputs": [],
         "source": [
            "if len(prompts_test) == 2:\n",
            "    prompts_test = prompts_train.copy()\n",
            "    summaries_test = summaries_train.copy()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d58184fe-945a-444f-a08a-af5730ae1b8c",
         "metadata": {},
         "source": [
            "### Visualize datasets"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e57fe004-d94f-47da-bca7-5bb41c6655e4",
         "metadata": {},
         "outputs": [],
         "source": [
            "prompts_test"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "849166ae-6155-4a7b-97bc-eb3aaf6a8b15",
         "metadata": {},
         "outputs": [],
         "source": [
            "summaries_test.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9ff1dea6-15a4-47b9-8dd3-d62ec2916772",
         "metadata": {},
         "source": [
            "### Inference"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "52ce2535-352a-44c7-a89b-9543ec49ba1f",
         "metadata": {},
         "source": [
            "### Normilized function\n",
            "usefull to normalize between -1 and 1 content and wording"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "42c5567e-299c-4deb-a83e-7da1e4ff9e23",
         "metadata": {},
         "outputs": [],
         "source": [
            "def normalize_value(x, min=-2, max=4):\n",
            "    return 2*((x-min)/(max-min))-1"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a0d550ab-3b27-4d9d-af4b-6e2f9019f58c",
         "metadata": {},
         "source": [
            "inverse normalization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2ea4ce44-8824-437d-aab2-1a0a36bd5886",
         "metadata": {},
         "outputs": [],
         "source": [
            "# def rescale(value, old_min=-1, old_max=1, new_min=-2, new_max=4):\n",
            "#     return ((value - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "4cd29a58-3be8-482a-a61c-17bc0a071613",
         "metadata": {},
         "source": [
            "### Helpers"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1a4090ea-68d5-421d-b2b7-af83a3d16ce6",
         "metadata": {},
         "outputs": [],
         "source": [
            "def to_numpy(var):\n",
            "    if isinstance(var, torch.Tensor):\n",
            "        return var.cpu().numpy()\n",
            "    return var"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1e46526a-2755-455e-a1fb-88f749a683a3",
         "metadata": {},
         "source": [
            "### Preprocess_prompts\n",
            "We do this separatly in order to preprocess only on time each row"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d0d34282-c9e8-4f79-b92e-acdf0de5055b",
         "metadata": {},
         "outputs": [],
         "source": [
            "def preprocess_prompts(prompts_df: pd.DataFrame) -> pd.DataFrame:\n",
            "    # init an empty new  dataFrame\n",
            "    new_data = pd.DataFrame({\n",
            "        'prompt_id': [],\n",
            "        'embeddings_question': [],\n",
            "        # 'prompt_title': [],\n",
            "        'embeddings_text': [],\n",
            "        'tf_idf': []\n",
            "    })\n",
            "\n",
            "    for index, row in prompts_df.iterrows():\n",
            "        # retrieve columns\n",
            "        prompt_id = row['prompt_id']\n",
            "        prompt_question = row['prompt_question']\n",
            "        # prompt_title = row['prompt_title'] # we do not need the title\n",
            "        prompt_text = row['prompt_text']\n",
            "\n",
            "        tf_idf = calc_tf_idf(prompt_question, prompt_text, 10)\n",
            "\n",
            "        # we are creating a batch of the sentences we want to get embeddings\n",
            "        sentences = [prompt_question, prompt_text]\n",
            "\n",
            "        # calling model embedding\n",
            "        embeddings = sentence_transformer_model.encode(sentences)\n",
            "\n",
            "        # Create a new row\n",
            "        new_row = pd.DataFrame({\n",
            "            'prompt_id': [prompt_id],\n",
            "            'embeddings_question': [embeddings[0]],\n",
            "            'embeddings_text': [embeddings[1]],\n",
            "            'tf_idf': [tf_idf],\n",
            "            'prompt_question': [prompt_question],\n",
            "            'prompt_text': [prompt_text]\n",
            "        })\n",
            "        \n",
            "        # Append the row\n",
            "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
            "\n",
            "    return new_data"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e70d8c27-20e1-4206-8384-80a11a87b6e6",
         "metadata": {},
         "source": [
            "### Preprocess one row to create the input"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e3d0889d-d0c9-4d94-b917-09bdc0bd0814",
         "metadata": {},
         "outputs": [],
         "source": [
            "def preprocess(row, prompts_df: pd.DataFrame):\n",
            "    # retrieve columns from summaries_df\n",
            "    prompt_id = row[\"prompt_id\"]\n",
            "    text = row[\"text\"]\n",
            "\n",
            "    # Data engineering\n",
            "    # space behind period of end of sentence \"Exemple end.Start new sentence text@gmail.com\" = \"Exemple end. Start new sentence text@gmail.com\" \n",
            "    text = re.sub(r'(?<=\\.)[A-Z]', r' \\g<0>', text)\n",
            "    text = Add_Periods(text)\n",
            "    \n",
            "    # FK_grade, Gunning_Fog, SMOG = readability_scores(text)\n",
            "    smog_index = getattr(textstat, 'smog_index')(text)\n",
            "    coleman_liau_index = getattr(textstat, 'coleman_liau_index')(text)\n",
            "    flesch_reading_ease = getattr(textstat, 'flesch_reading_ease')(text)\n",
            "    \n",
            "    lexical_density = Lexical_Density(text)\n",
            "    spell_checker = spell_checker_score(text)\n",
            "    \n",
            "    avg_word_length = average_word_length(text)\n",
            "\n",
            "    # we are creating a batch of the sentences we want to get embeddings\n",
            "    sentences = [row[\"text\"]]\n",
            "\n",
            "    # calling model embedding\n",
            "    embeddings = sentence_transformer_model.encode(sentences)\n",
            "    embeddings_answer = torch.tensor(embeddings[0])\n",
            "    \n",
            "    # retrieve usefull columns from preprocessed prompt\n",
            "    prompt_row = prompts_df.loc[prompts_df['prompt_id'] == prompt_id]\n",
            "    embeddings_question, embeddings_text = torch.tensor(prompt_row['embeddings_question'].item()), torch.tensor(prompt_row['embeddings_text'].item())\n",
            "    \n",
            "    # Calculating tf_idf for prompt question and prompt text in relation with answere text word present in the text\n",
            "    tf_idf = [word.lower() for word in prompt_row['tf_idf'].item()]\n",
            "    tf_idf_question = [word.lower() for word in calc_tf_idf(prompt_row[\"prompt_question\"].item(), text, 10)]\n",
            "    \n",
            "    # Calculate the score representing the number of words from prompt_tf_idf present in answer_tf_idf\n",
            "    tf_idf_question_score = sum(word in tf_idf_question for word in tf_idf)\n",
            "\n",
            "    features = (\n",
            "        torch.tensor([[normalize_value(lexical_density, min=0, max=1)]]).to(device), \\\n",
            "        torch.tensor([[normalize_value(spell_checker, min=0, max=10)]]).to(device), \\\n",
            "        torch.tensor([[normalize_value(tf_idf_question_score, min=0, max=10)]]).to(device), \\\n",
            "        torch.tensor([[normalize_value(avg_word_length, min=3, max=10)]]).to(device), \\\n",
            "        torch.tensor([[normalize_value(smog_index, min=0, max=17)]]).to(device), \\\n",
            "        torch.tensor([[normalize_value(coleman_liau_index, min=0, max=17)]]).to(device), \\\n",
            "        torch.tensor([[normalize_value(flesch_reading_ease, min=1, max=100)]]).to(device) \\\n",
            "       )\n",
            "    # Create input\n",
            "    input = torch.cat(\n",
            "        (\n",
            "            embeddings_text,\n",
            "            embeddings_question,\n",
            "            embeddings_answer\n",
            "        ), dim=0).unsqueeze(0).to(device)\n",
            "\n",
            "    return input, \\\n",
            "        features\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "fe65b522-ddde-46bd-a926-e91d2bc961a9",
         "metadata": {},
         "source": [
            "### Inference"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b2f6f7dc-a8b0-4335-89f1-c4e6026b7041",
         "metadata": {},
         "outputs": [],
         "source": [
            "def inference(summaries_df: pd.DataFrame, prompts_df: pd.DataFrame):\n",
            "    new_data = pd.DataFrame({\n",
            "        'student_id': [],\n",
            "        'content': [],\n",
            "        # 'prompt_title': [],\n",
            "        'wording': []\n",
            "    })\n",
            "\n",
            "    # preprocess prompt\n",
            "    prompts_df = preprocess_prompts(prompts_df)\n",
            "    # Iterate over summaries\n",
            "    for index, row in summaries_df.iterrows():\n",
            "        print(f\"\\r{index+1}/{len(summaries_df)}\", end=\"\")\n",
            "        student_id = row['student_id']\n",
            "        \n",
            "        input, \\\n",
            "        features = preprocess(row, prompts_df)\n",
            "\n",
            "        outputs = loaded_model(input, features)\n",
            "        content, wording = outputs[0].detach().cpu().numpy()\n",
            "\n",
            "        new_row = pd.DataFrame({'student_id': [student_id], 'content': [content], 'wording': [wording]})\n",
            "\n",
            "        # Append the row\n",
            "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
            "    new_data.to_csv(submission_path, index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "6287d0b8-358e-4962-89d7-686e94729ee5",
         "metadata": {},
         "outputs": [],
         "source": [
            "inference(summaries_test, prompts_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "860d728c-4fc1-46ee-9c11-83e736fab300",
         "metadata": {},
         "source": [
            "## checking hist"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7affcdd8-7a44-4c9e-8c18-2856fdbd6c89",
         "metadata": {},
         "outputs": [],
         "source": [
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2897f4bd-92b4-4eed-b89c-4789495afc3f",
         "metadata": {},
         "outputs": [],
         "source": [
            "xmin, xmax = -2, 4\n",
            "ymin, ymax = 0, 2000"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1797d4f8-3394-4441-b6bf-c1f1ad49b31e",
         "metadata": {},
         "outputs": [],
         "source": [
            "df3['content'].hist(), df3['wording'].hist()\n",
            "\n",
            "df3['content'].hist(label='Content', alpha=0.5, edgecolor='k')\n",
            "df3['wording'].hist(label='Wording', alpha=0.5, edgecolor='k')\n",
            "# Adding a legend\n",
            "plt.legend()\n",
            "plt.title('Error')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "01acdf88-184e-4a8e-919c-6fc24427c265",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Calculate the overall average of 'content' and 'wording' columns\n",
            "avg_overall = df3[['content', 'wording']].mean().mean()\n",
            "print(f\"Overall Average: {avg_overall}\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9e2af7f2-42c7-4c80-9d71-3ac2874e6a1f",
         "metadata": {},
         "outputs": [],
         "source": [
            "submission_file = pd.read_csv(submission_path)\n",
            "\n",
            "submission_file['content'].hist(label='Content', alpha=0.5, edgecolor='k')\n",
            "submission_file['wording'].hist(label='Wording', alpha=0.5, edgecolor='k')\n",
            "plt.xlim([xmin, xmax])  # Set x-axis limits\n",
            "plt.ylim([ymin, ymax])  # Set y-axis limits\n",
            "# Adding a legend\n",
            "plt.legend()\n",
            "plt.title('Prediction')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "8d23267c-e2b6-48a2-9a6a-4c5efe1b25f6",
         "metadata": {},
         "outputs": [],
         "source": [
            "summaries_test['content'].hist(label='Content', alpha=0.5, edgecolor='k')\n",
            "summaries_test['wording'].hist(label='Wording', alpha=0.5, edgecolor='k')\n",
            "plt.xlim([xmin, xmax])  # Set x-axis limits\n",
            "plt.ylim([ymin, ymax])  # Set y-axis limits\n",
            "# Adding a legend\n",
            "plt.legend()\n",
            "plt.title('Real')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "19eb39e4-cba0-4663-9c68-eac7c7fc78d9",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.5"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}