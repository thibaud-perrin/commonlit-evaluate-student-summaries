{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a14353b-46a1-4c60-9ee7-080174af9aa7",
   "metadata": {},
   "source": [
    "# Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c8f10e2-148a-44e1-8cf6-748a75601885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2Model\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e45dabc-8015-4143-b354-2198a598f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27656d7a-a0cf-4693-a0b7-c046685ed806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "from spellchecker import SpellChecker\n",
    "from lexical_density import lexical_density as Lexical_Density\n",
    "from TF_IDF import calc_tf_idf\n",
    "from Add_Periods import Add_Periods\n",
    "from avg_word_sentence_length import average_word_length, average_sentence_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e5e25-bb6f-453b-86b5-addc6cc72a7a",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06b53bf-a6eb-4fce-af1d-814fc0a022ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 30 16:06:11 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.99                 Driver Version: 536.99       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1070      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 28%   39C    P8              11W / 151W |    701MiB /  8192MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2472    C+G   ...Brave-Browser\\Application\\brave.exe    N/A      |\n",
      "|    0   N/A  N/A      5720    C+G   ...ejd91yc\\AdobeNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A      7964    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     10252    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14396    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     15452    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16592    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     18416    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     19580    C+G   ...Data\\Local\\Programs\\Blitz\\Blitz.exe    N/A      |\n",
      "|    0   N/A  N/A     23144    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A     24372    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     27180    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     27656    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     30980    C+G   ...7.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A     30984    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28da5a7c-b1ca-4bd3-b7c9-77a6137bb795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available, else use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd7321-ba11-4a3a-b3f4-70ec0c7f33b3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742575e5-761a-4eee-8cae-e0bee0b4803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_checker_score(text, debug = False):\n",
    "    def remove_punctuation(st):\n",
    "        return re.sub(f\"[{re.escape(string.punctuation)}]\", '', st)\n",
    "    \n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(remove_punctuation(text).split())\n",
    "\n",
    "    if debug:\n",
    "        for word in misspelled:\n",
    "            # Get the one `most likely` answer\n",
    "            print(f\"{word} => {spell.correction(word)}\")\n",
    "        \n",
    "        print(f\"misspelled: {len(misspelled)}\")\n",
    "    return len(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b83692bd-f88a-4d3c-8994-79dbf2c4bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTransformer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentenceTransformer, self).__init__()\n",
    "        # Load the tokenizer and model\n",
    "        self.tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "        self.model = DebertaV2Model.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    def encode(self, sentences):\n",
    "        # Tokenize sentences\n",
    "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "            \n",
    "        # Only take the embeddings of the [CLS] token (or use the mean of the token embeddings if desired)\n",
    "        sentence_embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b514473a-1693-45e7-a0f0-edc56398cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "deberta = SentenceTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1622b6e4-c1b0-4ac2-8f69-ccbb8004feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1804,  0.2592,  0.0357, -0.1198,  0.1036]])\n",
      "tensor([[ 0.1804,  0.2592,  0.0357, -0.1198,  0.1036]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "text = \"Hugging Face is creating a tool that democratizes AI.\"\n",
    "embedding = get_embedding(text)\n",
    "print(embedding[:, :5])\n",
    "print(deberta.encode(text)[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66a6ae3c-0e78-409a-ae07-b575f344dc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " {'input_ids': [1, 88419, 510, 8834, 269, 1512, 266, 1637, 272, 92146, 268, 5536, 260, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deberta.tokenizer(text)['input_ids']), deberta.tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd958f-82f1-4f6b-9a00-97c41e225c30",
   "metadata": {},
   "source": [
    "## Generate dataset and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d7c30-5744-4c0d-824d-dcc667e50a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, device):\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "\n",
    "    def deserialize_array(self, binary_string, dtype, shape):\n",
    "        return np.frombuffer(binary_string, dtype=dtype).reshape(shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        # retrieve values\n",
    "        student_id = data['student_id']\n",
    "        prompt_id = data['prompt_id']\n",
    "        embeddings_question = torch.tensor(self.deserialize_array(data['embeddings_question'], np.float32, (768,))).to(self.device)\n",
    "        embeddings_text = torch.tensor(self.deserialize_array(data['embeddings_text'], np.float32, (768,))).to(self.device)\n",
    "        text = torch.tensor(self.deserialize_array(data['text'], np.float32, (768,))).to(self.device)\n",
    "        content = torch.tensor(data['content']).to(self.device)\n",
    "        wording = torch.tensor(data['wording']).to(self.device)\n",
    "        normalized_content = torch.tensor(data['normalized_content']).to(self.device)\n",
    "        normalized_wording = torch.tensor(data['normalized_wording']).to(self.device)\n",
    "        normalized_lexical_density = torch.tensor(data['normalized_lexical_density']).unsqueeze(0).to(self.device)\n",
    "        normalized_spell_checker = torch.tensor(data['normalized_spell_checker']).unsqueeze(0).to(self.device)\n",
    "        normalized_tf_idf_question_score = torch.tensor(data['normalized_tf_idf_question_score']).unsqueeze(0).to(self.device)\n",
    "        normalized_avg_word_length = torch.tensor(data['normalized_avg_word_length']).unsqueeze(0).to(self.device)\n",
    "        normalized_smog_index = torch.tensor(data['normalized_smog_index']).unsqueeze(0).to(self.device)\n",
    "        normalized_coleman_liau_index = torch.tensor(data['normalized_coleman_liau_index']).unsqueeze(0).to(self.device)\n",
    "        normalized_flesch_reading_ease = torch.tensor(data['normalized_flesch_reading_ease']).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        return {\n",
    "            'student_id': student_id,\n",
    "            'prompt_id': prompt_id,\n",
    "            'embeddings_question': embeddings_question,\n",
    "            'embeddings_text': embeddings_text,\n",
    "            'text': text,\n",
    "            'content': content,\n",
    "            'wording': wording,\n",
    "            'normalized_content': normalized_content,\n",
    "            'normalized_wording': normalized_wording,\n",
    "            'normalized_lexical_density': normalized_lexical_density,\n",
    "            'normalized_spell_checker': normalized_spell_checker,\n",
    "            'normalized_tf_idf_question_score': normalized_tf_idf_question_score,\n",
    "            'normalized_avg_word_length': normalized_avg_word_length,\n",
    "            'normalized_smog_index': normalized_smog_index,\n",
    "            'normalized_coleman_liau_index': normalized_coleman_liau_index,\n",
    "            'normalized_flesch_reading_ease': normalized_flesch_reading_ease,\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int :\n",
    "        return self.dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e316c-df6c-485f-8561-6f890c556f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderFactory():\n",
    "\n",
    "    def __init__(self, path:str = './data/hugging_face', batch_size = 12, device = 'cpu'):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = load_from_disk(path, keep_in_memory=True)\n",
    "        self.device = device\n",
    "\n",
    "        print(\"1. Loading dataset: ...\", end=\"\")\n",
    "        dataset = load_from_disk(path, keep_in_memory=True)\n",
    "        print(\"\\r1. Loading dataset: done ✔️\")\n",
    "\n",
    "        print(\"2. Split datasets: ...\", end=\"\")\n",
    "        train_validation_splits = self.dataset['train'].train_test_split(test_size=0.2)\n",
    "        print(\"\\r2. Preprocess datasets: done ✔️\")\n",
    "\n",
    "        print(\"3. Split datasets: ...\", end=\"\")\n",
    "        self.train_data = PromptDataset(train_validation_splits['train'], self.device)\n",
    "        self.val_data = PromptDataset(train_validation_splits['test'], self.device)\n",
    "        print(\"\\r3. Split datasets: done ✔️\")\n",
    "\n",
    "        self.dataloader_train = DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n",
    "        self.dataloader_val = DataLoader(self.val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int :\n",
    "        print(\"\\033[95m\\033[1m\\033[4mNumber of data by datasets splits\\033[0m\")\n",
    "        print(f\"Train\\t\\t: {len(self.train_data)}\\t-> {len(self.train_data)/self.batch_size}\")\n",
    "        print(f\"Validation\\t: {len(self.val_data)}\\t\\t-> {len(self.val_data)/self.batch_size}\")\n",
    "        total = len(self.train_data) + len(self.val_data)\n",
    "        print(f\"Total\\t\\t: {total}\")\n",
    "        return total\n",
    "\n",
    "    def get_batch(self, split):\n",
    "        # choose the correct dataloader\n",
    "        if split == 'train':\n",
    "            dataloader = self.dataloader_train\n",
    "        else:\n",
    "            dataloader = self.dataloader_val\n",
    "\n",
    "        for batch in dataloader:\n",
    "            # Move tensors to device\n",
    "            batch_on_device = {k: v for k, v in batch.items()}\n",
    "            yield batch_on_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f4fc8-1830-4fab-ae74-d12fb945f374",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67182de-ccb8-4f77-87e0-5c88be245435",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoaderFactory(device=device)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e512f-1fad-4c54-80c5-c0500a25f086",
   "metadata": {},
   "source": [
    "### Testing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded6cee-24b5-4d28-a3df-a857fd1336c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset.get_batch('train')\n",
    "nb = next(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8f919-4ba2-46be-be03-d47b248ddd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'student_id:':<25}{len(nb['student_id'])}\")\n",
    "print(f\"{'prompt_id:':<25}{len(nb['prompt_id'])}\")\n",
    "print(f\"{'embeddings_question:':<25}{nb['embeddings_question'].shape}\")\n",
    "print(f\"{'embeddings_text:':<25}{nb['embeddings_text'].shape}\")\n",
    "print(f\"{'text:':<25}{nb['text'].shape}\")\n",
    "print(f\"{'content:':<25}{nb['content'].shape}\")\n",
    "print(f\"{'wording:':<25}{nb['wording'].shape}\")\n",
    "print(f\"{'normalized_content:':<25}{nb['normalized_content'].shape}\")\n",
    "print(f\"{'normalized_wording:':<25}{nb['normalized_wording'].shape}\")\n",
    "print(f\"{'normalized_lexical_density:':<25}{nb['normalized_lexical_density'].shape}\")\n",
    "print(f\"{'normalized_spell_checker:':<25}{nb['normalized_spell_checker'].shape}\")\n",
    "print(f\"{'normalized_tf_idf_question_score:':<25}{nb['normalized_tf_idf_question_score'].shape}\")\n",
    "print(f\"{'normalized_avg_word_length:':<25}{nb['normalized_avg_word_length'].shape}\")\n",
    "print(f\"{'normalized_smog_index:':<25}{nb['normalized_smog_index'].shape}\")\n",
    "print(f\"{'normalized_coleman_liau_index:':<25}{nb['normalized_coleman_liau_index'].shape}\")\n",
    "print(f\"{'normalized_flesch_reading_ease:':<25}{nb['normalized_flesch_reading_ease'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90125960-7f7e-48e8-a57b-1c3169e3de62",
   "metadata": {},
   "source": [
    "## Kaggle evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89aa4c-b050-4dd8-8f4b-070fe574653c",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c94f7-c78a-4c41-9480-9bcc996d1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_train_path = \"./data/prompts_train.csv\"\n",
    "prompts_test_path = \"./data/prompts_test.csv\"\n",
    "\n",
    "summaries_train_path = \"./data/summaries_train.csv\"\n",
    "summaries_test_path = \"./data/summaries_test.csv\"\n",
    "\n",
    "model_path = \"./out/best_model_script.pt\"\n",
    "\n",
    "submission_path = \"./out/submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbd7cd-e0dc-434b-98d7-e433116855d4",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ed7ae-5764-402f-a29a-101ad1a83234",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple_batches = dataset.get_batch('train')\n",
    "ex_batch = next(exemple_batches)\n",
    "embeddings_question = ex_batch['embeddings_question']\n",
    "embeddings_text = ex_batch['embeddings_text']\n",
    "text = ex_batch['text']\n",
    "\n",
    "normalized_content = ex_batch['normalized_content']\n",
    "normalized_wording = ex_batch['normalized_wording']\n",
    "\n",
    "normalized_lexical_density = ex_batch['normalized_lexical_density']\n",
    "normalized_spell_checker = ex_batch['normalized_spell_checker']\n",
    "normalized_tf_idf_question_score = ex_batch['normalized_tf_idf_question_score']\n",
    "normalized_avg_word_length = ex_batch['normalized_avg_word_length']\n",
    "normalized_smog_index = ex_batch['normalized_smog_index']\n",
    "normalized_coleman_liau_index = ex_batch['normalized_coleman_liau_index']\n",
    "normalized_flesch_reading_ease = ex_batch['normalized_flesch_reading_ease']\n",
    "\n",
    "example_input_tensor = torch.cat(\n",
    "    (\n",
    "        embeddings_question,\n",
    "        embeddings_text,\n",
    "        text,\n",
    "        normalized_lexical_density,\n",
    "        normalized_spell_checker,\n",
    "        normalized_tf_idf_question_score,\n",
    "        normalized_avg_word_length,\n",
    "        normalized_smog_index,\n",
    "        normalized_coleman_liau_index,\n",
    "        normalized_flesch_reading_ease\n",
    "    ), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce749a10-ac04-4447-abb3-de63a86b039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.jit.load(model_path).to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcb9db-726b-4cc6-adec-f961b958a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model(example_input_tensor.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0aef4-bdaa-46ef-86ae-40f2b829cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1, tensor2 = loaded_model(example_input_tensor.to(device)), torch.stack((normalized_content, normalized_wording), dim=1)\n",
    "\n",
    "for (col1_tensor1, col2_tensor1), (col1_tensor2, col2_tensor2) in zip(tensor1, tensor2):\n",
    "    print(f\"[{col1_tensor1:>6.3f} => {col1_tensor2:>6.3f} = {col1_tensor2-col1_tensor1:>6.3f}] \\t | \\t [{col2_tensor1:>6.3f} => {col2_tensor2:>6.3f} = {col2_tensor2 - col2_tensor1:>6.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c3f66-776f-4fff-8491-ed02133ee807",
   "metadata": {},
   "source": [
    "### Load SentenceTransformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4baffed-cbc7-4f13-bc26-e3334e4adb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d0706-e52f-4c64-bef2-1985c089a4b5",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4a847-4cbe-4386-b4fc-202ddeec7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_train = pd.read_csv(prompts_train_path)\n",
    "prompts_test = pd.read_csv(prompts_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661771f2-7416-45fb-923d-aa04ee72f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train = pd.read_csv(summaries_train_path)\n",
    "summaries_test = pd.read_csv(summaries_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8adba-7a33-463b-ac55-65dfc0c6cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(prompts_test) == 2:\n",
    "    prompts_test = prompts_train.copy()\n",
    "    summaries_test = summaries_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58184fe-945a-444f-a08a-af5730ae1b8c",
   "metadata": {},
   "source": [
    "### Visualize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fe004-d94f-47da-bca7-5bb41c6655e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849166ae-6155-4a7b-97bc-eb3aaf6a8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1dea6-15a4-47b9-8dd3-d62ec2916772",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce2535-352a-44c7-a89b-9543ec49ba1f",
   "metadata": {},
   "source": [
    "### Normilized function\n",
    "usefull to normalize between -1 and 1 content and wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5567e-299c-4deb-a83e-7da1e4ff9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(x, min=-2, max=4):\n",
    "    return 2*((x-min)/(max-min))-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d550ab-3b27-4d9d-af4b-6e2f9019f58c",
   "metadata": {},
   "source": [
    "inverse normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4ce44-8824-437d-aab2-1a0a36bd5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(value, old_min=-1, old_max=1, new_min=-2, new_max=4):\n",
    "    return ((value - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd29a58-3be8-482a-a61c-17bc0a071613",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4090ea-68d5-421d-b2b7-af83a3d16ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(var):\n",
    "    if isinstance(var, torch.Tensor):\n",
    "        return var.cpu().numpy()\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46526a-2755-455e-a1fb-88f749a683a3",
   "metadata": {},
   "source": [
    "### Preprocess_prompts\n",
    "We do this separatly in order to preprocess only on time each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d34282-c9e8-4f79-b92e-acdf0de5055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_prompts(prompts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # init an empty new  dataFrame\n",
    "    new_data = pd.DataFrame({\n",
    "        'prompt_id': [],\n",
    "        'embeddings_question': [],\n",
    "        # 'prompt_title': [],\n",
    "        'embeddings_text': []\n",
    "    })\n",
    "\n",
    "    for index, row in prompts_df.iterrows():\n",
    "        # retrieve columns\n",
    "        prompt_id = row['prompt_id']\n",
    "        prompt_question = row['prompt_question']\n",
    "        # prompt_title = row['prompt_title'] # we do not need the title\n",
    "        prompt_text = row['prompt_text']\n",
    "\n",
    "        tf_idf = calc_tf_idf(prompt_question, prompt_text, 10)\n",
    "\n",
    "        # we are creating a batch of the sentences we want to get embeddings\n",
    "        sentences = [prompt_question, prompt_text]\n",
    "\n",
    "        # calling model embedding\n",
    "        embeddings = sentence_transformer_model.encode(sentences)\n",
    "\n",
    "        # Create a new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'prompt_id': [prompt_id],\n",
    "            'embeddings_question': [embeddings[0]],\n",
    "            'embeddings_text': [embeddings[1]],\n",
    "            'tf_idf': [tf_idf],\n",
    "            'prompt_question': [prompt_question],\n",
    "            'prompt_text': [prompt_text]\n",
    "        })\n",
    "        \n",
    "        # Append the row\n",
    "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d8c27-20e1-4206-8384-80a11a87b6e6",
   "metadata": {},
   "source": [
    "### Preprocess one row to create the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0889d-d0c9-4d94-b917-09bdc0bd0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row, prompts_df: pd.DataFrame):\n",
    "    # retrieve columns from summaries_df\n",
    "    prompt_id = row[\"prompt_id\"]\n",
    "    text = row[\"text\"]\n",
    "\n",
    "    # Data engineering\n",
    "    # space behind period of end of sentence \"Exemple end.Start new sentence text@gmail.com\" = \"Exemple end. Start new sentence text@gmail.com\" \n",
    "    text = re.sub(r'(?<=\\.)[A-Z]', r' \\g<0>', text)\n",
    "    text = Add_Periods(text)\n",
    "    \n",
    "    # FK_grade, Gunning_Fog, SMOG = readability_scores(text)\n",
    "    smog_index = getattr(textstat, 'smog_index')(text)\n",
    "    coleman_liau_index = getattr(textstat, 'coleman_liau_index')(text)\n",
    "    flesch_reading_ease = getattr(textstat, 'flesch_reading_ease')(text)\n",
    "    \n",
    "    lexical_density = Lexical_Density(text)\n",
    "    spell_checker = spell_checker_score(text)\n",
    "    \n",
    "    avg_word_length = average_word_length(text)\n",
    "\n",
    "    # we are creating a batch of the sentences we want to get embeddings\n",
    "    sentences = [text]\n",
    "\n",
    "    # calling model embedding\n",
    "    embeddings = sentence_transformer_model.encode(sentences)\n",
    "    text_embedding = torch.tensor(embeddings[0])\n",
    "    \n",
    "    # retrieve usefull columns from preprocessed prompt\n",
    "    prompt_row = prompts_df.loc[prompts_df['prompt_id'] == prompt_id]\n",
    "    embeddings_question, embeddings_text = torch.tensor(prompt_row['embeddings_question'].item()), torch.tensor(prompt_row['embeddings_text'].item())\n",
    "\n",
    "    \n",
    "    # Calculating tf_idf for prompt question and prompt text in relation with answere text word present in the text\n",
    "    tf_idf = [word.lower() for word in prompt_row['tf_idf'].item()]\n",
    "    tf_idf_question = [word.lower() for word in calc_tf_idf(prompt_row[\"prompt_question\"].item(), text, 10)]\n",
    "    \n",
    "    # Calculate the score representing the number of words from prompt_tf_idf present in answer_tf_idf\n",
    "    tf_idf_question_score = sum(word in tf_idf_question for word in tf_idf)\n",
    "\n",
    "    # Create input\n",
    "    input = torch.cat(\n",
    "        (\n",
    "            embeddings_question, # Prompt_question\n",
    "            embeddings_text, # prompt_text\n",
    "            text_embedding, # text\n",
    "            torch.tensor(normalize_value(lexical_density, min=0, max=1)).unsqueeze(0),\n",
    "            torch.tensor(normalize_value(spell_checker, min=0, max=10)).unsqueeze(0),\n",
    "            torch.tensor(normalize_value(tf_idf_question_score, min=0, max=10)).unsqueeze(0),\n",
    "            torch.tensor(normalize_value(avg_word_length, min=3, max=10)).unsqueeze(0),\n",
    "            torch.tensor(normalize_value(smog_index, min=0, max=17)).unsqueeze(0),\n",
    "            torch.tensor(normalize_value(coleman_liau_index, min=0, max=17)).unsqueeze(0),\n",
    "            torch.tensor(normalize_value(flesch_reading_ease, min=1, max=100)).unsqueeze(0)\n",
    "        ), dim=0).unsqueeze(0).to(device)\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65b522-ddde-46bd-a926-e91d2bc961a9",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6f7dc-a8b0-4335-89f1-c4e6026b7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(summaries_df: pd.DataFrame, prompts_df: pd.DataFrame):\n",
    "    new_data = pd.DataFrame({\n",
    "        'student_id': [],\n",
    "        'content': [],\n",
    "        # 'prompt_title': [],\n",
    "        'wording': []\n",
    "    })\n",
    "\n",
    "    # preprocess prompt\n",
    "    prompts_df = preprocess_prompts(prompts_df)\n",
    "    # Iterate over summaries\n",
    "    for index, row in summaries_df.iterrows():\n",
    "        print(f\"\\r{index+1}/{len(summaries_df)}\", end=\"\")\n",
    "        student_id = row['student_id']\n",
    "        input = preprocess(row, prompts_df)\n",
    "\n",
    "        outputs = loaded_model(input)\n",
    "        content, wording = outputs[0].detach().cpu().numpy()\n",
    "\n",
    "        new_row = pd.DataFrame({'student_id': [student_id], 'content': [rescale(content)], 'wording': [rescale(wording)]})\n",
    "\n",
    "        # Append the row\n",
    "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
    "    new_data.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287d0b8-358e-4962-89d7-686e94729ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(summaries_test, prompts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d728c-4fc1-46ee-9c11-83e736fab300",
   "metadata": {},
   "source": [
    "## checking hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affcdd8-7a44-4c9e-8c18-2856fdbd6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897f4bd-92b4-4eed-b89c-4789495afc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -2, 4\n",
    "ymin, ymax = 0, 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797d4f8-3394-4441-b6bf-c1f1ad49b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_file = pd.read_csv(submission_path)\n",
    "submission_file['content'].hist()\n",
    "plt.xlim([xmin, xmax])  # Set x-axis limits\n",
    "plt.ylim([ymin, ymax])  # Set y-axis limits\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acdf88-184e-4a8e-919c-6fc24427c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file['wording'].hist()\n",
    "plt.xlim([xmin, xmax])  # Set x-axis limits\n",
    "plt.ylim([ymin, ymax])  # Set y-axis limits\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2af7f2-42c7-4c80-9d71-3ac2874e6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_test['content'].hist()\n",
    "plt.xlim([xmin, xmax])  # Set x-axis limits\n",
    "plt.ylim([ymin, ymax])  # Set y-axis limits\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23267c-e2b6-48a2-9a6a-4c5efe1b25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_test['wording'].hist()\n",
    "plt.xlim([xmin, xmax])  # Set x-axis limits\n",
    "plt.ylim([ymin, ymax])  # Set y-axis limits\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c262a-704b-4719-8b5d-b6ba9a25dc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
