{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0fdb40-dc96-4b04-9eb5-6846058124fb",
   "metadata": {},
   "source": [
    "# Generate HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a892dd-38d2-4c00-a8e0-0b3e0391b453",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfbd222-4caa-464b-aa3b-f3658a4d31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from spellchecker import SpellChecker\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806bdef1-ca61-4b2a-b919-cbafb28f5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original sys.path\n",
    "original_sys_path = list(sys.path)\n",
    "sys.path.append('..')\n",
    "\n",
    "from readability_scores import readability_scores\n",
    "from lexical_density import lexical_density as Lexical_Density\n",
    "from avg_word_sentence_length import average_word_length, average_sentence_length\n",
    "from introduce_typo import introduce_typo\n",
    "from TF_IDF import calc_tf_idf\n",
    "from Add_Periods import Add_Periods\n",
    "\n",
    "# Restore the original sys.path\n",
    "sys.path = original_sys_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf65511-03e9-440f-bd5f-687c95e15a64",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9fb2e6-4779-418d-aaac-3344690c6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = '../out'\n",
    "DATA_PATH = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca02c3-66c8-4e12-8b8e-d1c9ac9a0ebe",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0e2ba-dce3-4158-acf5-a4312178d4d9",
   "metadata": {},
   "source": [
    "### Loading prompts train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "658f083e-84de-4f19-9bb8-2345aef61752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\nAs the sequel to what has already...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\nThe Third Wave experiment took pl...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train = pd.read_csv(f\"{DATA_PATH}/prompts_train.csv\")\n",
    "prompts_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d60e40-914a-4e7b-995a-79a7ffefbe14",
   "metadata": {},
   "source": [
    "### Loading summaries train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78557809-6251-4aa2-ab96-70870966c218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  \n",
       "0  0.205683  0.380538  \n",
       "1 -0.548304  0.506755  \n",
       "2  3.128928  4.231226  \n",
       "3 -0.210614 -0.471415  \n",
       "4  3.272894  3.219757  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_train = pd.read_csv(f\"{DATA_PATH}/summaries_train.csv\")\n",
    "summaries_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46afa9e-d997-4079-853b-0ea73a1043d3",
   "metadata": {},
   "source": [
    "## Readability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ec9d1e-15ce-4d3d-8e0f-14577b3d53c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 23.13\n",
      "Gunning Fog Index: 26.50\n",
      "SMOG Index: 21.19\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Although the algorithmic approach to readability has been criticized for not taking into account \n",
    "         the deeper, more fluid aspects of comprehension, such as motivation, background knowledge, \n",
    "         and personal interest, it's a useful tool for getting a general gauge on text's complexity.\"\"\"\n",
    "\n",
    "FK_grade, Gunning_Fog, SMOG = readability_scores(text)\n",
    "print(f\"Flesch-Kincaid Grade Level: {FK_grade:.2f}\")\n",
    "print(f\"Gunning Fog Index: {Gunning_Fog:.2f}\")\n",
    "print(f\"SMOG Index: {SMOG:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e626ade-0bdc-49cd-bb92-1e705228b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thz quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "noisy_text = introduce_typo(text, probability=0.2)\n",
    "print(noisy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcea6c3-f955-47ee-b31b-6146d46aeb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dale_chall_readability_score Grade Level: 5.84\n",
      "coleman_liau_index Index: 3.51\n",
      "gunning_fog Index: 3.60\n",
      "smog_index Index: 0.00\n"
     ]
    }
   ],
   "source": [
    "smog_index = getattr(textstat, 'smog_index')(text)\n",
    "gunning_fog = getattr(textstat, 'gunning_fog')(text)\n",
    "coleman_liau_index = getattr(textstat, 'coleman_liau_index')(text)\n",
    "dale_chall_readability_score = getattr(textstat, 'dale_chall_readability_score')(text)\n",
    "\n",
    "\n",
    "print(f\"dale_chall_readability_score Grade Level: {dale_chall_readability_score:.2f}\")\n",
    "print(f\"coleman_liau_index Index: {coleman_liau_index:.2f}\")\n",
    "print(f\"gunning_fog Index: {gunning_fog:.2f}\")\n",
    "print(f\"smog_index Index: {smog_index:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d0f64-010e-41a2-8aef-38c686a0de79",
   "metadata": {},
   "source": [
    "## Lexical density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9111542b-8731-4d78-8bf8-fee86bb65c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Density: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "text = \"The cat sat on the mat. The dog sat beside the cat.\"\n",
    "print(f\"Lexical Density: {Lexical_Density(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a4458-571c-4012-8398-57a80208f0ba",
   "metadata": {},
   "source": [
    "## avg_word_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f35aa542-2253-4d91-aef7-d560e312ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Length: 5.09\n",
      "Average Sentence Length (in words): 5.50\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello world! This is a test. How long is the average sentence? Let's find out.\"\n",
    "\n",
    "print(f\"Average Word Length: {average_word_length(text):.2f}\")\n",
    "print(f\"Average Sentence Length (in words): {average_sentence_length(text):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2015e-ab08-4f09-934f-d12ca3c638ee",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d500b2-535e-4a4f-9d8a-7474a6bb2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    'question': ['What is the theme of the text?'],\n",
    "    'text': [\"The short story revolves around a young girl's struggle during the Great Depression.\"]\n",
    "}\n",
    "data2 = {\n",
    "    'question': ['Where did the event occur?'],\n",
    "    'text': [ \"The documentary narrates events in a small town in Spain during the 1800s.\"]\n",
    "}\n",
    "data3 = {\n",
    "    'question': ['Who is the main character?'],\n",
    "    'text': [\"The novel centers on the adventures of a sailor named Odysseus.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cd5237-d54c-42d6-83f8-b228633048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    'question': prompts_train.loc[0]['prompt_question'],\n",
    "    'text': prompts_train.loc[0]['prompt_text']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aacc902-59be-4769-81f4-a1eca71dc18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Summarize at least 3 elements of an ideal tragedy, as described by Aristotle.',\n",
       " 'text': 'Chapter 13 \\nAs the sequel to what has already been said, we must proceed to consider what the poet should aim at, and what he should avoid, in constructing his plots; and by what means the specific effect of Tragedy will be produced. \\nA perfect tragedy should, as we have seen, be arranged not on the simple but on the complex plan. It should, moreover, imitate actions which excite pity and fear, this being the distinctive mark of tragic imitation. It follows plainly, in the first place, that the change of fortune presented must not be the spectacle of a virtuous man brought from prosperity to adversity: for this moves neither pity nor fear; it merely shocks us. Nor, again, that of a bad man passing from adversity to prosperity: for nothing can be more alien to the spirit of Tragedy; it possesses no single tragic quality; it neither satisfies the moral sense nor calls forth pity or fear. Nor, again, should the downfall of the utter villain be exhibited. A plot of this kind would, doubtless, satisfy the moral sense, but it would inspire neither pity nor fear; for pity is aroused by unmerited misfortune, fear by the misfortune of a man like ourselves. Such an event, therefore, will be neither pitiful nor terrible. There remains, then, the character between these two extremes — that of a man who is not eminently good and just, yet whose misfortune is brought about not by vice or depravity, but by some error of judgement or frailty. He must be one who is highly renowned and prosperous — a personage like Oedipus, Thyestes, or other illustrious men of such families. \\nA well-constructed plot should, therefore, be single in its issue, rather than double as some maintain. The change of fortune should be not from bad to good, but, reversely, from good to bad. It should come about as the result not of vice, but of some great error or frailty, in a character either such as we have described, or better rather than worse. The practice of the stage bears out our view. At first the poets recounted any legend that came in their way. Now, the best tragedies are founded on the story of a few houses — on the fortunes of Alcmaeon, Oedipus, Orestes, Meleager, Thyestes, Telephus, and those others who have done or suffered something terrible. A tragedy, then, to be perfect according to the rules of art, should be of this construction. Hence they are in error who censure Euripides just because he follows this principle in his plays, many of which end unhappily. It is, as we have said, the right ending. The best proof is that on the stage and in dramatic competition, such plays, if well worked out, are the most tragic in effect; and Euripides, faulty though he may be in the general management of his subject, yet is felt to be the most tragic of the poets. \\nIn the second rank comes the kind of tragedy which some place first. Like the Odyssey, it has a double thread of plot, and also an opposite catastrophe for the good and for the bad. It is accounted the best because of the weakness of the spectators; for the poet is guided in what he writes by the wishes of his audience. The pleasure, however, thence derived is not the true tragic pleasure. It is proper rather to Comedy, where those who, in the piece, are the deadliest enemies — like Orestes and Aegisthus — quit the stage as friends at the close, and no one slays or is slain.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b8b28c-7606-4262-913d-5b3f558a9eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tragedy',\n",
       " 'tragic',\n",
       " 'fear',\n",
       " 'pity',\n",
       " 'good',\n",
       " 'like',\n",
       " 'bad',\n",
       " 'man',\n",
       " 'best',\n",
       " 'stage']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_df = calc_tf_idf(data['question'], data['text'], 10)\n",
    "word_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260abe11-34b1-4755-b2f6-314313ca032a",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac1c332c-994c-4a07-b861-d71cf063f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2.922636103151863), (1, 0.9742120343839542), (2, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "class BM25:\n",
    "    def __init__(self, corpus, k1=1.5, b=0.75):\n",
    "        self.corpus = corpus\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.doc_lengths = [len(doc.split()) for doc in corpus]\n",
    "        self.avgdl = sum(self.doc_lengths) / len(corpus)\n",
    "\n",
    "    def score(self, query, doc):\n",
    "        \"\"\"\n",
    "        Compute BM25 score for a given document and query.\n",
    "        \"\"\"\n",
    "        doc_tokens = doc.split()\n",
    "        query_tokens = query.split()\n",
    "        score = 0.0\n",
    "        \n",
    "        for token in query_tokens:\n",
    "            f = doc_tokens.count(token)\n",
    "            score += (f * (self.k1 + 1)) / (f + self.k1 * (1 - self.b + self.b * len(doc_tokens) / self.avgdl))\n",
    "            \n",
    "        return score\n",
    "\n",
    "    def rank(self, query):\n",
    "        \"\"\"\n",
    "        Rank documents with respect to the given query.\n",
    "        \"\"\"\n",
    "        scores = [(i, self.score(query, doc)) for i, doc in enumerate(self.corpus)]\n",
    "        return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Example\n",
    "corpus = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog sat on the log\",\n",
    "    \"Cats and dogs are animals\"\n",
    "]\n",
    "\n",
    "bm25 = BM25(corpus)\n",
    "query = \"cat on mat\"\n",
    "ranking = bm25.rank(query)\n",
    "print(ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "713d48e3-c7ca-4b55-9f9f-6e455e22ee22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize at least 3 elements of an ideal tragedy, as described by Aristotle.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda98bbf-a491-42cf-9782-b73aa6acaa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A tragedy, then, to be perfect according to the rules of art, should be of this construction.\n",
      "\n",
      "2. It should come about as the result not of vice, but of some great error or frailty, in a character either such as we have described, or better rather than worse.\n",
      "\n",
      "3. It is accounted the best because of the weakness of the spectators; for the poet is guided in what he writes by the wishes of his audience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "query, text = data['question'], data['text']\n",
    "# Splitting the provided text into sentences\n",
    "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text.replace('\\r\\n', ' '))\n",
    "# Applying BM25 to rank sentences\n",
    "bm25 = BM25(sentences)\n",
    "ranking = bm25.rank(query)\n",
    "# Getting top 3 ranked sentence s\n",
    "top_sentences = [sentences[i[0]] for i in ranking[:3]]\n",
    "\n",
    "for i, sentence in enumerate(top_sentences, 1):\n",
    "    print(f\"{i}. {sentence}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b6b76-11a5-4892-97b8-72141411f139",
   "metadata": {},
   "source": [
    "**TODO: replace text with BM25 and do BM25 on answere and compare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "763bdffa-8402-4171-9d3a-b49bb819f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_id                                                     39c16e\n",
       "prompt_question    Summarize at least 3 elements of an ideal trag...\n",
       "prompt_title                                              On Tragedy\n",
       "prompt_text        Chapter 13 \\nAs the sequel to what has already...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d5beebb-43c3-403f-bfe2-1f3f8f267ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As described by Aristotle, three elements of an ideal tragedy would be that the plot should feature the downfall of a man who is not completely evil but who has a flaw which causes his downfall, that it should cause fear and pity in the audience, and that it should have a complex plot, but not a plot with two thread that has two different catastrophes for the good and the bad.  Aristotle  believes that the goal of a tragedy is to \"imitate actions which excite pity and fear\" and argues that in order for the tragedy to accomplish this goal, it should feature the downfall of a hero \"who is neiter eminently good and just, yet whose misfortune is brought on not by vice or depravity, but by some error of judgement or frailty.\" He thinks that if the hero were purely good, his downfall would simply be shocking to the audience, whereas the downfall of a purely evil man would not arouse pity or fear, since \"pity is aroused by unmerited misfortune, fear by the misfortune of a man like ourselves\" and the audience would instead derive moral satisfaction from seeing the evil man get what he deserved. Finally, Aristotle writes that while a tragedy should \"be arranged not only the simple but on the complex plan\" but that there should not be a \"double thread of plot, and also an opposite catastrophe for the good and bad\" because in that case the sense of pleasure from the audience will not be \"true tragic pleasure\" but closer to what the audience would feel when watching a comedy.\n"
     ]
    }
   ],
   "source": [
    "print(summaries_train.loc[summaries_train['content'] >= 3.9]['text'].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e68519-3660-46e9-8415-53ba4410353f",
   "metadata": {},
   "source": [
    "## SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "457f5cae-03fc-4abd-b83e-182a36ce3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_checker_score(text, debug = False):\n",
    "    def remove_punctuation(st):\n",
    "        return re.sub(f\"[{re.escape(string.punctuation)}]\", '', st)\n",
    "    \n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(remove_punctuation(text).split())\n",
    "\n",
    "    if debug:\n",
    "        for word in misspelled:\n",
    "            # Get the one `most likely` answer\n",
    "            print(f\"{word} => {spell.correction(word)}\")\n",
    "        \n",
    "        print(f\"misspelled: {len(misspelled)}\")\n",
    "    return len(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8fc55e3-3104-433f-b0cb-2f310b8a8c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meleager => mileage\n",
      "— => i\n",
      "reversely => reverse\n",
      "wellconstructed => None\n",
      "telephus => None\n",
      "thyestes => theses\n",
      "alcmaeon => None\n",
      "unmerited => inherited\n",
      "aegisthus => None\n",
      "misspelled: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checker_score(data['text'], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383de2d-db1e-4ff5-8339-fc03d7fbf0e8",
   "metadata": {},
   "source": [
    "## Generate HF Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d7844-375b-454d-8e87-042f3da13fad",
   "metadata": {},
   "source": [
    "### Load sentence transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496f00a9-3e1f-4587-b21d-62f79c33d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0602d7a-04fd-46c8-95f5-4eb0af28f196",
   "metadata": {},
   "source": [
    "### Preprocess prompts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e04c8112-8b95-4f30-acdf-35054384aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_prompts(prompts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # init an empty new  dataFrame\n",
    "    new_data = pd.DataFrame({\n",
    "        'prompt_id': [],\n",
    "        'prompt_question': [],\n",
    "        # 'prompt_title': [],\n",
    "        'prompt_text': [],\n",
    "        'tf_idf': []\n",
    "    })\n",
    "\n",
    "    for index, row in prompts_df.iterrows():\n",
    "        # retrieve columns\n",
    "        prompt_id = row['prompt_id']\n",
    "        prompt_question = row['prompt_question']\n",
    "        # prompt_title = row['prompt_title'] # we do not need the title\n",
    "        prompt_text = row['prompt_text']\n",
    "\n",
    "        tf_idf = calc_tf_idf(prompt_question, prompt_text, 10)\n",
    "\n",
    "        # we are creating a batch of the sentences we want to get embeddings\n",
    "        sentences = [prompt_question, prompt_text]\n",
    "\n",
    "        # calling model embedding\n",
    "        embeddings = model.encode(sentences)\n",
    "\n",
    "        # Create a new row\n",
    "        new_row = pd.DataFrame({'prompt_id': [prompt_id], 'embeddings_question': [embeddings[0]], 'embeddings_text': [embeddings[1]], 'tf_idf': [tf_idf], 'prompt_question': [prompt_question],  'prompt_text': [prompt_text]})\n",
    "        \n",
    "        # Append the row\n",
    "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
    "\n",
    "    path = f\"{DATA_PATH}/preprocessed_data\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    new_data.to_pickle(f\"{path}/prompts_train.pickle\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2542520c-d671-4014-834a-7886f48569c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>embeddings_question</th>\n",
       "      <th>embeddings_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
       "      <td>[tragedy, tragic, fear, pity, good, like, bad,...</td>\n",
       "      <td>[0.009159929, -0.02981883, 0.003172977, 0.0030...</td>\n",
       "      <td>[-0.010795927, 0.02571041, -0.015630055, 0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>[gods, pharaoh, farmers, government, pharaohs,...</td>\n",
       "      <td>[-0.012024662, 0.016922267, 0.015488319, 0.002...</td>\n",
       "      <td>[0.0580674, 0.042484548, 0.012715502, 0.006711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
       "      <td>[students, jones, movement, experiment, class,...</td>\n",
       "      <td>[0.05465699, -0.06503343, 0.011860327, -0.0535...</td>\n",
       "      <td>[0.047223743, 0.06517053, 0.000320501, -0.0252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>[meat, sausage, hams, spoiled, rats, packers, ...</td>\n",
       "      <td>[0.0067966105, 0.07661593, -0.009160588, 0.033...</td>\n",
       "      <td>[-0.013152143, 0.059951805, -0.0068048513, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\nAs the sequel to what has already...   \n",
       "1  Egyptian society was structured like a pyramid...   \n",
       "2  Background \\nThe Third Wave experiment took pl...   \n",
       "3  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "                                              tf_idf  \\\n",
       "0  [tragedy, tragic, fear, pity, good, like, bad,...   \n",
       "1  [gods, pharaoh, farmers, government, pharaohs,...   \n",
       "2  [students, jones, movement, experiment, class,...   \n",
       "3  [meat, sausage, hams, spoiled, rats, packers, ...   \n",
       "\n",
       "                                 embeddings_question  \\\n",
       "0  [0.009159929, -0.02981883, 0.003172977, 0.0030...   \n",
       "1  [-0.012024662, 0.016922267, 0.015488319, 0.002...   \n",
       "2  [0.05465699, -0.06503343, 0.011860327, -0.0535...   \n",
       "3  [0.0067966105, 0.07661593, -0.009160588, 0.033...   \n",
       "\n",
       "                                     embeddings_text  \n",
       "0  [-0.010795927, 0.02571041, -0.015630055, 0.010...  \n",
       "1  [0.0580674, 0.042484548, 0.012715502, 0.006711...  \n",
       "2  [0.047223743, 0.06517053, 0.000320501, -0.0252...  \n",
       "3  [-0.013152143, 0.059951805, -0.0068048513, -0....  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_prompts_train = preprocess_prompts(prompts_train)\n",
    "preprocessed_prompts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "523ec650-7831-4824-89c7-a5f1e87589ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine the two arrays of words and convert them to lowercase\n",
    "A = ['bonjour', 'salut', 'manger', 'hello']\n",
    "B = ['Gourmandise', 'Bonjour', 'How', 'salut', 'HELLO', 'trip']\n",
    "\n",
    "A_lower = [word.lower() for word in A]\n",
    "B_lower = [word.lower() for word in B]\n",
    "\n",
    "# Calculate the score representing the number of words from A present in B\n",
    "score = sum(word in B_lower for word in A_lower)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfc8f7-0988-4001-8a67-1ea89d46d48c",
   "metadata": {},
   "source": [
    "### Preprocess summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfa88488-5738-4b1a-baa6-49313f0a05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(x, min=-2, max=4):\n",
    "    return 2*((x-min)/(max-min))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbf96349-ab2e-4c2f-8be0-66fdbcd68fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_summaries(summaries_df: pd.DataFrame, prompts_df: pd.DataFrame) -> pd.DataFrame :\n",
    "    # init an empty new  dataFrame\n",
    "    new_data = pd.DataFrame({\n",
    "        'student_id': [],\n",
    "        'prompt_id': [],\n",
    "        'embeddings_question': [],\n",
    "        'embeddings_text': [],\n",
    "        'text': [],\n",
    "        'smog_index': [],\n",
    "        'coleman_liau_index': [],\n",
    "        'flesch_reading_ease': [],\n",
    "        'spell_checker': [],\n",
    "        'tf_idf_question_score': [],\n",
    "        'lexical_density': [],\n",
    "        'avg_word_length': [],\n",
    "        'content': [],\n",
    "        'wording': []\n",
    "    })\n",
    "    \n",
    "    for index, row in summaries_df.iterrows():\n",
    "        print(f\"\\r{index+1}/{len(summaries_df)}\", end=\"\")\n",
    "        # retrieve columns\n",
    "        student_id = row[\"student_id\"]\n",
    "        prompt_id = row[\"prompt_id\"]\n",
    "        text = row[\"text\"]\n",
    "        content = row[\"content\"]\n",
    "        wording = row[\"wording\"]\n",
    "        # space behind period of end of sentence \"Exemple end.Start new sentence text@gmail.com\" = \"Exemple end. Start new sentence text@gmail.com\" \n",
    "        text = re.sub(r'(?<=\\.)[A-Z]', r' \\g<0>', text)\n",
    "        text = Add_Periods(text)\n",
    "        \n",
    "        # FK_grade, Gunning_Fog, SMOG = readability_scores(text)\n",
    "        smog_index = getattr(textstat, 'smog_index')(text)\n",
    "        coleman_liau_index = getattr(textstat, 'coleman_liau_index')(text)\n",
    "        flesch_reading_ease = getattr(textstat, 'flesch_reading_ease')(text)\n",
    "        \n",
    "        lexical_density = Lexical_Density(text)\n",
    "        spell_checker = spell_checker_score(text)\n",
    "        \n",
    "        avg_word_length = average_word_length(text)\n",
    "\n",
    "        # we are creating a batch of the sentences we want to get embeddings\n",
    "        sentences = [row[\"text\"]]\n",
    "\n",
    "        # calling model embedding\n",
    "        embeddings = model.encode(sentences)\n",
    "\n",
    "        prompt_row = prompts_df.loc[prompts_df['prompt_id'] == prompt_id]\n",
    "        embeddings_question, embeddings_text = prompt_row['embeddings_question'].item(), prompt_row['embeddings_text'].item()\n",
    "\n",
    "        # Calculating tf_idf for prompt question and prompt text in relation with answere text word present in the text\n",
    "        tf_idf = [word.lower() for word in prompt_row['tf_idf'].item()]\n",
    "        tf_idf_question = [word.lower() for word in calc_tf_idf(prompt_row[\"prompt_question\"].item(), text, 10)]\n",
    "        \n",
    "        # Calculate the score representing the number of words from prompt_tf_idf present in answer_tf_idf\n",
    "        tf_idf_question_score = sum(word in tf_idf_question for word in tf_idf)\n",
    "\n",
    "        # Create a new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'student_id': [student_id],\n",
    "            'prompt_id': [prompt_id],\n",
    "            'embeddings_question': [embeddings_question],\n",
    "            'embeddings_text': [embeddings_text],\n",
    "            'text': [embeddings[0]],\n",
    "            'smog_index': [smog_index],\n",
    "            'coleman_liau_index': [coleman_liau_index],\n",
    "            'flesch_reading_ease': [flesch_reading_ease],\n",
    "            'lexical_density': [lexical_density],\n",
    "            'spell_checker': [spell_checker],\n",
    "            'tf_idf_question_score': [tf_idf_question_score],\n",
    "            'avg_word_length': [avg_word_length],\n",
    "            'content': [content],\n",
    "            'wording': [wording],\n",
    "        })\n",
    "        \n",
    "        # Append the row\n",
    "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
    "\n",
    "    path = f\"{DATA_PATH}/preprocessed_data\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    new_data.to_pickle(f\"{path}/summaries_train.pickle\") \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1ca60-ce30-4fe2-8b16-13b5b4677814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5554/7165"
     ]
    }
   ],
   "source": [
    "preprocess_summaries_train = preprocess_summaries(summaries_train, preprocessed_prompts_train)\n",
    "preprocess_summaries_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae12e4f-8b44-4641-beb4-9e58f01b7187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_summaries_train['content'] = normalize_value(preprocess_summaries_train['content'], min=-10, max=10)\n",
    "preprocess_summaries_train['wording'] = normalize_value(preprocess_summaries_train['wording'], min=-10, max=10)\n",
    "preprocess_summaries_train['normalized_lexical_density'] = normalize_value(preprocess_summaries_train['lexical_density'], min=0, max=1)\n",
    "preprocess_summaries_train['normalized_lexical_density'] = normalize_value(preprocess_summaries_train['lexical_density'], min=0, max=1)\n",
    "preprocess_summaries_train['normalized_spell_checker'] = normalize_value(preprocess_summaries_train['spell_checker'], min=0, max=10)\n",
    "preprocess_summaries_train['normalized_tf_idf_question_score'] = normalize_value(preprocess_summaries_train['tf_idf_question_score'], min=0, max=10)\n",
    "preprocess_summaries_train['normalized_avg_word_length'] = normalize_value(preprocess_summaries_train['avg_word_length'], min=3, max=10)\n",
    "preprocess_summaries_train['normalized_smog_index'] = normalize_value(preprocess_summaries_train['smog_index'], min=0, max=17)\n",
    "preprocess_summaries_train['normalized_coleman_liau_index'] = normalize_value(preprocess_summaries_train['coleman_liau_index'], min=0, max=17)\n",
    "preprocess_summaries_train['normalized_flesch_reading_ease'] = normalize_value(preprocess_summaries_train['flesch_reading_ease'], min=1, max=100)\n",
    "preprocess_summaries_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fadca1-8f14-4a5d-887d-5e6108f0194a",
   "metadata": {},
   "source": [
    "### Saving data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d245a-73e0-4092-b2a9-635a278b3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{DATA_PATH}/preprocessed_data\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "preprocess_summaries_train.to_pickle(f\"{path}/summaries_train.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bed5c0-3f74-49e7-80e6-96a45ef6e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"prompt_question: \", prompts_train['prompt_question'].apply(lambda x: len(x.split())).min(), prompts_train['prompt_question'].apply(lambda x: len(x.split())).max())\n",
    "print(\"prompt_text: \", prompts_train['prompt_text'].apply(lambda x: len(x.split())).min(), prompts_train['prompt_text'].apply(lambda x: len(x.split())).max())\n",
    "print(\"smog_index: \", preprocess_summaries_train['smog_index'].min(), preprocess_summaries_train['smog_index'].max())\n",
    "print(\"coleman_liau_index: \", preprocess_summaries_train['coleman_liau_index'].min(), preprocess_summaries_train['coleman_liau_index'].max())\n",
    "print(\"flesch_reading_ease: \", preprocess_summaries_train['flesch_reading_ease'].min(), preprocess_summaries_train['flesch_reading_ease'].max())\n",
    "print(\"lexical_density: \", preprocess_summaries_train['lexical_density'].min(), preprocess_summaries_train['lexical_density'].max())\n",
    "print(\"spell_checker: \", preprocess_summaries_train['spell_checker'].min(), preprocess_summaries_train['spell_checker'].max())\n",
    "print(\"tf_idf_question_score: \", preprocess_summaries_train['tf_idf_question_score'].min(), preprocess_summaries_train['tf_idf_question_score'].max())\n",
    "print(\"avg_word_length: \", preprocess_summaries_train['avg_word_length'].min(), preprocess_summaries_train['avg_word_length'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d3a39-9a3f-4717-b64b-312075350baa",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e4264-9f12-4280-afb1-a7246e9211b7",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64b78c-4ae8-459c-a5a3-dba69775d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a43195-bf0f-4dec-bbea-fe698757a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_summaries_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd3c63-1f89-42ef-93a2-112670dd3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = preprocess_summaries_train[[\n",
    "    'normalized_smog_index',\n",
    "    'normalized_coleman_liau_index',\n",
    "    'normalized_flesch_reading_ease',\n",
    "    'content',\n",
    "    'wording',\n",
    "    'normalized_lexical_density',\n",
    "    'normalized_spell_checker',\n",
    "    'normalized_tf_idf_question_score',\n",
    "    'normalized_avg_word_length',\n",
    "]]\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = corr_df.corr()\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f85435-854d-472f-b7a3-ba18e3b56e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify the indices of 'content' and 'wording'\n",
    "content_index = corr_df.columns.get_loc('content')\n",
    "wording_index = corr_df.columns.get_loc('wording')\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = corr_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "\n",
    "position = 0\n",
    "\n",
    "# Add borders around 'content' and 'wording' rows and columns\n",
    "plt.gca().add_patch(plt.Rectangle((content_index-position, 0), 2, correlation_matrix.shape[0], fill=False, edgecolor='black', lw=1))\n",
    "plt.gca().add_patch(plt.Rectangle((0, content_index), correlation_matrix.shape[1], 2, fill=False, edgecolor='black', lw=1))\n",
    "plt.gca().add_patch(plt.Rectangle((content_index, content_index), 2, 2, fill=True, facecolor='darkred', edgecolor='darkred', lw=1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2934301-a745-469b-8346-efdab0f389f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.to_json(f\"{DATA_PATH}/corr.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86cc04a-4dd9-4024-9f02-e902938c0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_summaries_train = pd.read_pickle(f\"{DATA_PATH}/preprocessed_data/summaries_train.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218939e4-182a-4c19-9b0c-0be1dd4a4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_summaries_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194de095-ba2c-4ca2-bdf7-be3e9204b92a",
   "metadata": {},
   "source": [
    "### Serialize and deserialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081d7c2-f824-4643-8769-e9e400f64552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_array(arr):\n",
    "    return arr.tobytes()\n",
    "    \n",
    "def deserialize_array(binary_string, dtype, shape):\n",
    "    return np.frombuffer(binary_string, dtype=dtype).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664ef03-0b0e-45f3-87cf-e8f464015c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data['embeddings_question'] = data['embeddings_question'].apply(serialize_array)\n",
    "    data['embeddings_text'] = data['embeddings_text'].apply(serialize_array)\n",
    "    data['text'] = data['text'].apply(serialize_array)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5be9f-43b1-4614-a6ed-676aaf632f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_summaries_train = preprocess_data(preprocess_summaries_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432a82c-ba06-41a9-b153-06eda8530afc",
   "metadata": {},
   "source": [
    "### Converting the pandas dataset to huggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff22dd7-c9eb-4dd5-95ac-2b0169d74aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(preprocess_summaries_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55ee54-ca5f-46ab-93dc-c3c2988abcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': train_dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72994f5b-f125-4640-b6c6-c4f25610dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict(dataset)\n",
    "path = f\"{DATA_PATH}/hugging_face/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b311976-aa79-41db-997d-f2e8f6f1c1a1",
   "metadata": {},
   "source": [
    "### Test the HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80070679-e2df-490c-b8b2-55be5beb36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later you can load the entire DatasetDict back from disk like this\n",
    "dataset_dict = DatasetDict.load_from_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d10c37-4863-4434-a853-7b2a77a8d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_dict)\n",
    "print()\n",
    "print(deserialize_array(dataset_dict['train'][0]['embeddings_question'], np.float32, (768)).shape)\n",
    "print()\n",
    "print(deserialize_array(dataset_dict['train'][0]['embeddings_text'], np.float32, (768)).shape)\n",
    "print()\n",
    "print(deserialize_array(dataset_dict['train'][0]['text'], np.float32, (768)).shape)\n",
    "print()\n",
    "print(dataset_dict['train'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0e410-bd14-4ac3-9998-8e51a4f83580",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f818764-e1e3-44e6-bb29-b3f4ae0d036c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
