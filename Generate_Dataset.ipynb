{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0fdb40-dc96-4b04-9eb5-6846058124fb",
   "metadata": {},
   "source": [
    "# Generate HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a892dd-38d2-4c00-a8e0-0b3e0391b453",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfbd222-4caa-464b-aa3b-f3658a4d31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806bdef1-ca61-4b2a-b919-cbafb28f5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readability_scores import readability_scores\n",
    "from lexical_density import lexical_density as Lexical_Density\n",
    "from avg_word_sentence_length import average_word_length, average_sentence_length\n",
    "from introduce_typo import introduce_typo\n",
    "from TF_IDF import calc_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca02c3-66c8-4e12-8b8e-d1c9ac9a0ebe",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0e2ba-dce3-4158-acf5-a4312178d4d9",
   "metadata": {},
   "source": [
    "### Loading prompts train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658f083e-84de-4f19-9bb8-2345aef61752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train = pd.read_csv('./data/prompts_train.csv')\n",
    "prompts_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d60e40-914a-4e7b-995a-79a7ffefbe14",
   "metadata": {},
   "source": [
    "### Loading summaries train csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78557809-6251-4aa2-ab96-70870966c218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  \n",
       "0  0.205683  0.380538  \n",
       "1 -0.548304  0.506755  \n",
       "2  3.128928  4.231226  \n",
       "3 -0.210614 -0.471415  \n",
       "4  3.272894  3.219757  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_train = pd.read_csv('./data/summaries_train.csv')\n",
    "summaries_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46afa9e-d997-4079-853b-0ea73a1043d3",
   "metadata": {},
   "source": [
    "## Readability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ec9d1e-15ce-4d3d-8e0f-14577b3d53c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 23.03\n",
      "Gunning Fog Index: 25.32\n",
      "SMOG Index: 21.19\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Although the algorithmic approach to readability has been criticized for not taking into account \n",
    "         the deeper, more fluid aspects of comprehension, such as motivation, background knowledge, \n",
    "         and personal interest, it's a useful tool for getting a general gauge on text's complexity.\"\"\"\n",
    "\n",
    "FK_grade, Gunning_Fog, SMOG = readability_scores(text)\n",
    "print(f\"Flesch-Kincaid Grade Level: {FK_grade:.2f}\")\n",
    "print(f\"Gunning Fog Index: {Gunning_Fog:.2f}\")\n",
    "print(f\"SMOG Index: {SMOG:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e626ade-0bdc-49cd-bb92-1e705228b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick pbrown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "noisy_text = introduce_typo(text, probability=0.2)\n",
    "print(noisy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d0f64-010e-41a2-8aef-38c686a0de79",
   "metadata": {},
   "source": [
    "## Lexical density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9111542b-8731-4d78-8bf8-fee86bb65c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Density: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Example list of stop words. You can expand this list as needed.\n",
    "text = \"The cat sat on the mat. The dog sat beside the cat.\"\n",
    "\n",
    "print(f\"Lexical Density: {Lexical_Density(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a4458-571c-4012-8398-57a80208f0ba",
   "metadata": {},
   "source": [
    "## avg_word_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35aa542-2253-4d91-aef7-d560e312ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Length: 5.09\n",
      "Average Sentence Length (in words): 5.50\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello world! This is a test. How long is the average sentence? Let's find out.\"\n",
    "\n",
    "print(f\"Average Word Length: {average_word_length(text):.2f}\")\n",
    "print(f\"Average Sentence Length (in words): {average_sentence_length(text):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2015e-ab08-4f09-934f-d12ca3c638ee",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d500b2-535e-4a4f-9d8a-7474a6bb2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    'question': ['What is the theme of the text?'],\n",
    "    'text': [\"The short story revolves around a young girl's struggle during the Great Depression.\"]\n",
    "}\n",
    "data2 = {\n",
    "    'question': ['Where did the event occur?'],\n",
    "    'text': [ \"The documentary narrates events in a small town in Spain during the 1800s.\"]\n",
    "}\n",
    "data3 = {\n",
    "    'question': ['Who is the main character?'],\n",
    "    'text': [\"The novel centers on the adventures of a sailor named Odysseus.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74cd5237-d54c-42d6-83f8-b228633048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    'question': prompts_train.loc[0]['prompt_question'],\n",
    "    'text': prompts_train.loc[0]['prompt_text']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aacc902-59be-4769-81f4-a1eca71dc18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Summarize at least 3 elements of an ideal tragedy, as described by Aristotle.',\n",
       " 'text': 'Chapter 13 \\r\\nAs the sequel to what has already been said, we must proceed to consider what the poet should aim at, and what he should avoid, in constructing his plots; and by what means the specific effect of Tragedy will be produced. \\r\\nA perfect tragedy should, as we have seen, be arranged not on the simple but on the complex plan. It should, moreover, imitate actions which excite pity and fear, this being the distinctive mark of tragic imitation. It follows plainly, in the first place, that the change of fortune presented must not be the spectacle of a virtuous man brought from prosperity to adversity: for this moves neither pity nor fear; it merely shocks us. Nor, again, that of a bad man passing from adversity to prosperity: for nothing can be more alien to the spirit of Tragedy; it possesses no single tragic quality; it neither satisfies the moral sense nor calls forth pity or fear. Nor, again, should the downfall of the utter villain be exhibited. A plot of this kind would, doubtless, satisfy the moral sense, but it would inspire neither pity nor fear; for pity is aroused by unmerited misfortune, fear by the misfortune of a man like ourselves. Such an event, therefore, will be neither pitiful nor terrible. There remains, then, the character between these two extremes — that of a man who is not eminently good and just, yet whose misfortune is brought about not by vice or depravity, but by some error of judgement or frailty. He must be one who is highly renowned and prosperous — a personage like Oedipus, Thyestes, or other illustrious men of such families. \\r\\nA well-constructed plot should, therefore, be single in its issue, rather than double as some maintain. The change of fortune should be not from bad to good, but, reversely, from good to bad. It should come about as the result not of vice, but of some great error or frailty, in a character either such as we have described, or better rather than worse. The practice of the stage bears out our view. At first the poets recounted any legend that came in their way. Now, the best tragedies are founded on the story of a few houses — on the fortunes of Alcmaeon, Oedipus, Orestes, Meleager, Thyestes, Telephus, and those others who have done or suffered something terrible. A tragedy, then, to be perfect according to the rules of art, should be of this construction. Hence they are in error who censure Euripides just because he follows this principle in his plays, many of which end unhappily. It is, as we have said, the right ending. The best proof is that on the stage and in dramatic competition, such plays, if well worked out, are the most tragic in effect; and Euripides, faulty though he may be in the general management of his subject, yet is felt to be the most tragic of the poets. \\r\\nIn the second rank comes the kind of tragedy which some place first. Like the Odyssey, it has a double thread of plot, and also an opposite catastrophe for the good and for the bad. It is accounted the best because of the weakness of the spectators; for the poet is guided in what he writes by the wishes of his audience. The pleasure, however, thence derived is not the true tragic pleasure. It is proper rather to Comedy, where those who, in the piece, are the deadliest enemies — like Orestes and Aegisthus — quit the stage as friends at the close, and no one slays or is slain.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b8b28c-7606-4262-913d-5b3f558a9eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tragedy',\n",
       " 'tragic',\n",
       " 'fear',\n",
       " 'pity',\n",
       " 'good',\n",
       " 'like',\n",
       " 'bad',\n",
       " 'man',\n",
       " 'best',\n",
       " 'stage']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_df = calc_tf_idf(data['question'], data['text'], 10)\n",
    "word_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260abe11-34b1-4755-b2f6-314313ca032a",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1c332c-994c-4a07-b861-d71cf063f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2.922636103151863), (1, 0.9742120343839542), (2, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "class BM25:\n",
    "    def __init__(self, corpus, k1=1.5, b=0.75):\n",
    "        self.corpus = corpus\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.doc_lengths = [len(doc.split()) for doc in corpus]\n",
    "        self.avgdl = sum(self.doc_lengths) / len(corpus)\n",
    "\n",
    "    def score(self, query, doc):\n",
    "        \"\"\"\n",
    "        Compute BM25 score for a given document and query.\n",
    "        \"\"\"\n",
    "        doc_tokens = doc.split()\n",
    "        query_tokens = query.split()\n",
    "        score = 0.0\n",
    "        \n",
    "        for token in query_tokens:\n",
    "            f = doc_tokens.count(token)\n",
    "            score += (f * (self.k1 + 1)) / (f + self.k1 * (1 - self.b + self.b * len(doc_tokens) / self.avgdl))\n",
    "            \n",
    "        return score\n",
    "\n",
    "    def rank(self, query):\n",
    "        \"\"\"\n",
    "        Rank documents with respect to the given query.\n",
    "        \"\"\"\n",
    "        scores = [(i, self.score(query, doc)) for i, doc in enumerate(self.corpus)]\n",
    "        return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Example\n",
    "corpus = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog sat on the log\",\n",
    "    \"Cats and dogs are animals\"\n",
    "]\n",
    "\n",
    "bm25 = BM25(corpus)\n",
    "query = \"cat on mat\"\n",
    "ranking = bm25.rank(query)\n",
    "print(ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda98bbf-a491-42cf-9782-b73aa6acaa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A tragedy, then, to be perfect according to the rules of art, should be of this construction.\n",
      "\n",
      "2. It should come about as the result not of vice, but of some great error or frailty, in a character either such as we have described, or better rather than worse.\n",
      "\n",
      "3. It is accounted the best because of the weakness of the spectators; for the poet is guided in what he writes by the wishes of his audience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "query, text = data['question'], data['text']\n",
    "# Splitting the provided text into sentences\n",
    "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text.replace('\\r\\n', ' '))\n",
    "# Applying BM25 to rank sentences\n",
    "bm25 = BM25(sentences)\n",
    "ranking = bm25.rank(query)\n",
    "# Getting top 3 ranked sentences\n",
    "top_sentences = [sentences[i[0]] for i in ranking[:3]]\n",
    "\n",
    "for i, sentence in enumerate(top_sentences, 1):\n",
    "    print(f\"{i}. {sentence}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383de2d-db1e-4ff5-8339-fc03d7fbf0e8",
   "metadata": {},
   "source": [
    "## Generate HF Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d7844-375b-454d-8e87-042f3da13fad",
   "metadata": {},
   "source": [
    "### Load sentence transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "496f00a9-3e1f-4587-b21d-62f79c33d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0602d7a-04fd-46c8-95f5-4eb0af28f196",
   "metadata": {},
   "source": [
    "### Preprocess prompts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04c8112-8b95-4f30-acdf-35054384aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_prompts(prompts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # init an empty new  dataFrame\n",
    "    new_data = pd.DataFrame({\n",
    "        'prompt_id': [],\n",
    "        'prompt_question': [],\n",
    "        # 'prompt_title': [],\n",
    "        'prompt_text': []\n",
    "    })\n",
    "\n",
    "    for index, row in prompts_df.iterrows():\n",
    "        # retrieve columns\n",
    "        prompt_id = row['prompt_id']\n",
    "        prompt_question = row['prompt_question']\n",
    "        # prompt_title = row['prompt_title'] # we do not need the title\n",
    "        prompt_text = row['prompt_text']\n",
    "\n",
    "        # we are creating a batch of the sentences we want to get embeddings\n",
    "        sentences = [prompt_question, prompt_text]\n",
    "\n",
    "        # calling model embedding\n",
    "        embeddings = model.encode(sentences)\n",
    "\n",
    "        # Create a new row\n",
    "        new_row = pd.DataFrame({'prompt_id': [prompt_id], 'prompt_question': [embeddings[0]], 'prompt_text': [embeddings[1]]})\n",
    "        \n",
    "        # Append the row\n",
    "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
    "\n",
    "    path = f\"./data/preprocessed_data\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    new_data.to_pickle(f\"{path}/prompts_train.pickle\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2542520c-d671-4014-834a-7886f48569c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>[0.0091599105, -0.029818784, 0.0031730002, 0.0...</td>\n",
       "      <td>[-0.010795923, 0.025710443, -0.015630066, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>[0.054656938, -0.06503344, 0.011860348, -0.053...</td>\n",
       "      <td>[0.04722372, 0.06517054, 0.00032050064, -0.025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  [0.0091599105, -0.029818784, 0.0031730002, 0.0...   \n",
       "1    3b9047  [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "2    814d6b  [0.054656938, -0.06503344, 0.011860348, -0.053...   \n",
       "3    ebad26  [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  [-0.010795923, 0.025710443, -0.015630066, 0.01...  \n",
       "1  [0.058067385, 0.042484563, 0.012715496, 0.0067...  \n",
       "2  [0.04722372, 0.06517054, 0.00032050064, -0.025...  \n",
       "3  [-0.013152148, 0.059951786, -0.0068048476, -0....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_prompts_train = preprocess_prompts(prompts_train)\n",
    "preprocessed_prompts_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfc8f7-0988-4001-8a67-1ea89d46d48c",
   "metadata": {},
   "source": [
    "### Preprocess summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa88488-5738-4b1a-baa6-49313f0a05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(x, min=-2, max=4):\n",
    "    return 2*((x-min)/(max-min))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf96349-ab2e-4c2f-8be0-66fdbcd68fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_summaries(summaries_df: pd.DataFrame, prompts_df: pd.DataFrame) -> pd.DataFrame :\n",
    "    # init an empty new  dataFrame\n",
    "    new_data = pd.DataFrame({\n",
    "        'student_id': [],\n",
    "        'prompt_id': [],\n",
    "        'prompt_question': [],\n",
    "        'prompt_text': [],\n",
    "        'text': [],\n",
    "        'fk_grade': [],\n",
    "        'gunning_fog': [],\n",
    "        'smog': [],\n",
    "        'lexical_density': [],\n",
    "        'avg_word_length': [],\n",
    "        'avg_sentence_length': [],\n",
    "        'content': [],\n",
    "        'wording': [],\n",
    "        'normalized_content': [],\n",
    "        'normalized_wording': []\n",
    "    })\n",
    "    \n",
    "    for index, row in summaries_df.iterrows():\n",
    "        print(f\"\\r{index+1}/{len(summaries_df)}\", end=\"\")\n",
    "        # retrieve columns\n",
    "        student_id = row[\"student_id\"]\n",
    "        prompt_id = row[\"prompt_id\"]\n",
    "        text = row[\"text\"]\n",
    "        content = row[\"content\"]\n",
    "        wording = row[\"wording\"]\n",
    "        FK_grade, Gunning_Fog, SMOG = readability_scores(text)\n",
    "        lexical_density = Lexical_Density(text)\n",
    "        avg_word_length = average_word_length(text)\n",
    "        avg_sentence_length = average_sentence_length(text)\n",
    "        normalized_content = normalize_value(content)\n",
    "        normalized_wording = normalize_value(wording)\n",
    "\n",
    "        # we are creating a batch of the sentences we want to get embeddings\n",
    "        sentences = [text]\n",
    "\n",
    "        # calling model embedding\n",
    "        embeddings = model.encode(sentences)\n",
    "\n",
    "        prompt_row = prompts_df.loc[prompts_df['prompt_id'] == prompt_id]\n",
    "        prompt_question, prompt_text = prompt_row['prompt_question'].item(), prompt_row['prompt_text'].item()\n",
    "\n",
    "        # Create a new row\n",
    "        new_row = pd.DataFrame({\n",
    "            'student_id': [student_id],\n",
    "            'prompt_id': [prompt_id],\n",
    "            'prompt_question': [prompt_question],\n",
    "            'prompt_text': [prompt_text],\n",
    "            'text': [embeddings[0]],\n",
    "            'fk_grade': [FK_grade],\n",
    "            'gunning_fog': [Gunning_Fog],\n",
    "            'smog': [SMOG],\n",
    "            'lexical_density': [lexical_density],\n",
    "            'avg_word_length': [avg_word_length],\n",
    "            'avg_sentence_length': [avg_sentence_length],\n",
    "            'content': [content],\n",
    "            'wording': [wording],\n",
    "            'normalized_content': [normalized_content],\n",
    "            'normalized_wording': [normalized_wording]\n",
    "        })\n",
    "        \n",
    "        # Append the row\n",
    "        new_data = pd.concat([new_data.loc[:], new_row], ignore_index=True)\n",
    "\n",
    "    path = f\"./data/preprocessed_data\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    new_data.to_pickle(f\"{path}/summaries_train.pickle\") \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6c1ca60-ce30-4fe2-8b16-13b5b4677814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7165/7165"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>text</th>\n",
       "      <th>fk_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>normalized_content</th>\n",
       "      <th>normalized_wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[0.054656938, -0.06503344, 0.011860348, -0.053...</td>\n",
       "      <td>[0.04722372, 0.06517054, 0.00032050064, -0.025...</td>\n",
       "      <td>[0.041094355, -0.006460443, 0.008264857, -0.06...</td>\n",
       "      <td>9.002500</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>11.208143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>-0.264772</td>\n",
       "      <td>-0.206487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "      <td>[0.033534568, 0.112103865, 0.013419032, 0.0166...</td>\n",
       "      <td>5.524444</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.129100</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>-0.516101</td>\n",
       "      <td>-0.164415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[0.022079999, 0.030259458, 0.016786981, 0.0001...</td>\n",
       "      <td>9.238716</td>\n",
       "      <td>11.572072</td>\n",
       "      <td>11.374739</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>5.456989</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>0.709643</td>\n",
       "      <td>1.077075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[0.041241955, -0.01394414, 0.015658101, 0.0315...</td>\n",
       "      <td>4.160522</td>\n",
       "      <td>7.057391</td>\n",
       "      <td>7.554174</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>-0.403538</td>\n",
       "      <td>-0.490472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[0.054656938, -0.06503344, 0.011860348, -0.053...</td>\n",
       "      <td>[0.04722372, 0.06517054, 0.00032050064, -0.025...</td>\n",
       "      <td>[0.008337094, 0.04310772, 0.0132706165, -0.052...</td>\n",
       "      <td>10.254643</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>12.540901</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>5.712500</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>0.757631</td>\n",
       "      <td>0.739919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "      <td>[0.035653163, 0.043147907, -0.030623915, -0.00...</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>15.015385</td>\n",
       "      <td>13.023867</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>-0.264772</td>\n",
       "      <td>-0.206487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ffc34d056498</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[-0.035234254, 0.033364758, 0.02028155, 0.0068...</td>\n",
       "      <td>7.304138</td>\n",
       "      <td>6.625287</td>\n",
       "      <td>7.793538</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>6.034483</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>-0.436149</td>\n",
       "      <td>-0.317276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ffd1576d2e1b</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[0.022816774, 0.011155369, -0.0006411369, 0.02...</td>\n",
       "      <td>5.835000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.793538</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>-1.408180</td>\n",
       "      <td>-0.493603</td>\n",
       "      <td>-0.802727</td>\n",
       "      <td>-0.497868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ffe4a98093b2</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[0.0091599105, -0.029818784, 0.0031730002, 0.0...</td>\n",
       "      <td>[-0.010795923, 0.025710443, -0.015630066, 0.01...</td>\n",
       "      <td>[0.012417577, -0.052821647, -0.0033073293, -0....</td>\n",
       "      <td>6.465116</td>\n",
       "      <td>9.454264</td>\n",
       "      <td>9.725611</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>4.627907</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "      <td>-0.464437</td>\n",
       "      <td>-0.124291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "      <td>[0.0332336, 0.12647918, 0.0012254969, -0.01061...</td>\n",
       "      <td>6.554278</td>\n",
       "      <td>8.345316</td>\n",
       "      <td>8.238736</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>4.531646</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "      <td>0.257199</td>\n",
       "      <td>-0.150753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     000e8c3c7ddb    814d6b   \n",
       "1     0020ae56ffbf    ebad26   \n",
       "2     004e978e639e    3b9047   \n",
       "3     005ab0199905    3b9047   \n",
       "4     0070c9e7af47    814d6b   \n",
       "...            ...       ...   \n",
       "7160  ff7c7e70df07    ebad26   \n",
       "7161  ffc34d056498    3b9047   \n",
       "7162  ffd1576d2e1b    3b9047   \n",
       "7163  ffe4a98093b2    39c16e   \n",
       "7164  fffbccfd8a08    ebad26   \n",
       "\n",
       "                                        prompt_question  \\\n",
       "0     [0.054656938, -0.06503344, 0.011860348, -0.053...   \n",
       "1     [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "2     [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "3     [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "4     [0.054656938, -0.06503344, 0.011860348, -0.053...   \n",
       "...                                                 ...   \n",
       "7160  [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "7161  [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "7162  [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "7163  [0.0091599105, -0.029818784, 0.0031730002, 0.0...   \n",
       "7164  [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "0     [0.04722372, 0.06517054, 0.00032050064, -0.025...   \n",
       "1     [-0.013152148, 0.059951786, -0.0068048476, -0....   \n",
       "2     [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "3     [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "4     [0.04722372, 0.06517054, 0.00032050064, -0.025...   \n",
       "...                                                 ...   \n",
       "7160  [-0.013152148, 0.059951786, -0.0068048476, -0....   \n",
       "7161  [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "7162  [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "7163  [-0.010795923, 0.025710443, -0.015630066, 0.01...   \n",
       "7164  [-0.013152148, 0.059951786, -0.0068048476, -0....   \n",
       "\n",
       "                                                   text   fk_grade  \\\n",
       "0     [0.041094355, -0.006460443, 0.008264857, -0.06...   9.002500   \n",
       "1     [0.033534568, 0.112103865, 0.013419032, 0.0166...   5.524444   \n",
       "2     [0.022079999, 0.030259458, 0.016786981, 0.0001...   9.238716   \n",
       "3     [0.041241955, -0.01394414, 0.015658101, 0.0315...   4.160522   \n",
       "4     [0.008337094, 0.04310772, 0.0132706165, -0.052...  10.254643   \n",
       "...                                                 ...        ...   \n",
       "7160  [0.035653163, 0.043147907, -0.030623915, -0.00...  12.250000   \n",
       "7161  [-0.035234254, 0.033364758, 0.02028155, 0.0068...   7.304138   \n",
       "7162  [0.022816774, 0.011155369, -0.0006411369, 0.02...   5.835000   \n",
       "7163  [0.012417577, -0.052821647, -0.0033073293, -0....   6.465116   \n",
       "7164  [0.0332336, 0.12647918, 0.0012254969, -0.01061...   6.554278   \n",
       "\n",
       "      gunning_fog       smog  lexical_density  avg_word_length  \\\n",
       "0       11.466667  11.208143         0.875000         5.312500   \n",
       "1        7.200000   3.129100         0.805556         4.166667   \n",
       "2       11.572072  11.374739         0.731183         5.456989   \n",
       "3        7.057391   7.554174         0.800000         6.200000   \n",
       "4       14.071429  12.540901         0.787500         5.712500   \n",
       "...           ...        ...              ...              ...   \n",
       "7160    15.015385  13.023867         0.823529         5.000000   \n",
       "7161     6.625287   7.793538         0.862069         6.034483   \n",
       "7162     7.333333   7.793538         0.923077         5.000000   \n",
       "7163     9.454264   9.725611         0.813953         4.627907   \n",
       "7164     8.345316   8.238736         0.772152         4.531646   \n",
       "\n",
       "      avg_sentence_length   content   wording  normalized_content  \\\n",
       "0               12.000000  0.205683  0.380538           -0.264772   \n",
       "1               18.000000 -0.548304  0.506755           -0.516101   \n",
       "2               15.416667  3.128928  4.231226            0.709643   \n",
       "3                4.600000 -0.210614 -0.471415           -0.403538   \n",
       "4               12.307692  3.272894  3.219757            0.757631   \n",
       "...                   ...       ...       ...                 ...   \n",
       "7160            26.000000  0.205683  0.380538           -0.264772   \n",
       "7161             7.250000 -0.308448  0.048171           -0.436149   \n",
       "7162            13.333333 -1.408180 -0.493603           -0.802727   \n",
       "7163            14.333333 -0.393310  0.627128           -0.464437   \n",
       "7164            13.166667  1.771596  0.547742            0.257199   \n",
       "\n",
       "      normalized_wording  \n",
       "0              -0.206487  \n",
       "1              -0.164415  \n",
       "2               1.077075  \n",
       "3              -0.490472  \n",
       "4               0.739919  \n",
       "...                  ...  \n",
       "7160           -0.206487  \n",
       "7161           -0.317276  \n",
       "7162           -0.497868  \n",
       "7163           -0.124291  \n",
       "7164           -0.150753  \n",
       "\n",
       "[7165 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_summaries_train = preprocess_summaries(summaries_train, preprocessed_prompts_train)\n",
    "preprocess_summaries_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11bed5c0-3f74-49e7-80e6-96a45ef6e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_grade:  0.5360526315789471 52.19131782945736\n",
      "gunning_fog:  1.8 55.010852713178295\n",
      "smog:  3.1291 30.526468669271875\n",
      "lexical_density:  0.33181818181818185 1.0\n",
      "avg_word_length:  3.4782608695652173 8.057692307692308\n",
      "avg_sentence_length:  3.111111111111111 129.0\n"
     ]
    }
   ],
   "source": [
    "print(\"fk_grade: \", preprocess_summaries_train['fk_grade'].min(), preprocess_summaries_train['fk_grade'].max())\n",
    "print(\"gunning_fog: \", preprocess_summaries_train['gunning_fog'].min(), preprocess_summaries_train['gunning_fog'].max())\n",
    "print(\"smog: \", preprocess_summaries_train['smog'].min(), preprocess_summaries_train['smog'].max())\n",
    "print(\"lexical_density: \", preprocess_summaries_train['lexical_density'].min(), preprocess_summaries_train['lexical_density'].max())\n",
    "print(\"avg_word_length: \", preprocess_summaries_train['avg_word_length'].min(), preprocess_summaries_train['avg_word_length'].max())\n",
    "print(\"avg_sentence_length: \", preprocess_summaries_train['avg_sentence_length'].min(), preprocess_summaries_train['avg_sentence_length'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d3a39-9a3f-4717-b64b-312075350baa",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b2e81b9-bd44-4698-93c6-388f67af49ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id                                                  1c50ba91ffba\n",
       "prompt_id                                                         814d6b\n",
       "prompt_question        [0.054656938, -0.06503344, 0.011860348, -0.053...\n",
       "prompt_text            [0.04722372, 0.06517054, 0.00032050064, -0.025...\n",
       "text                   [0.048191037, 0.05854288, -0.0014909966, -0.04...\n",
       "fk_grade                                                       16.093193\n",
       "gunning_fog                                                    18.420168\n",
       "smog                                                           16.263093\n",
       "lexical_density                                                 0.767857\n",
       "avg_word_length                                                  6.14881\n",
       "avg_sentence_length                                            24.142857\n",
       "content                                                         3.711374\n",
       "wording                                                         4.064103\n",
       "normalized_content                                              0.903791\n",
       "normalized_wording                                              1.021368\n",
       "Name: 790, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_prompt_id = '814d6b'\n",
    "index_of_max_content = preprocess_summaries_train[preprocess_summaries_train['prompt_id'] == specific_prompt_id]['content'].idxmax()\n",
    "preprocess_summaries_train.loc[index_of_max_content]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e90da1-65aa-4aef-b950-c52efd29c852",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a86cc04a-4dd9-4024-9f02-e902938c0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_summaries_train = pd.read_pickle(\"./data/preprocessed_data/summaries_train.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "218939e4-182a-4c19-9b0c-0be1dd4a4e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>text</th>\n",
       "      <th>fk_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>normalized_content</th>\n",
       "      <th>normalized_wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[0.054656938, -0.06503344, 0.011860348, -0.053...</td>\n",
       "      <td>[0.04722372, 0.06517054, 0.00032050064, -0.025...</td>\n",
       "      <td>[0.041094355, -0.006460443, 0.008264857, -0.06...</td>\n",
       "      <td>9.002500</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>11.208143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>-0.264772</td>\n",
       "      <td>-0.206487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "      <td>[0.033534568, 0.112103865, 0.013419032, 0.0166...</td>\n",
       "      <td>5.524444</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.129100</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>-0.516101</td>\n",
       "      <td>-0.164415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[0.022079999, 0.030259458, 0.016786981, 0.0001...</td>\n",
       "      <td>9.238716</td>\n",
       "      <td>11.572072</td>\n",
       "      <td>11.374739</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>5.456989</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>0.709643</td>\n",
       "      <td>1.077075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[0.041241955, -0.01394414, 0.015658101, 0.0315...</td>\n",
       "      <td>4.160522</td>\n",
       "      <td>7.057391</td>\n",
       "      <td>7.554174</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>-0.403538</td>\n",
       "      <td>-0.490472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>[0.054656938, -0.06503344, 0.011860348, -0.053...</td>\n",
       "      <td>[0.04722372, 0.06517054, 0.00032050064, -0.025...</td>\n",
       "      <td>[0.008337094, 0.04310772, 0.0132706165, -0.052...</td>\n",
       "      <td>10.254643</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>12.540901</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>5.712500</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>0.757631</td>\n",
       "      <td>0.739919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "      <td>[0.035653163, 0.043147907, -0.030623915, -0.00...</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>15.015385</td>\n",
       "      <td>13.023867</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>-0.264772</td>\n",
       "      <td>-0.206487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ffc34d056498</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[-0.035234254, 0.033364758, 0.02028155, 0.0068...</td>\n",
       "      <td>7.304138</td>\n",
       "      <td>6.625287</td>\n",
       "      <td>7.793538</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>6.034483</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>-0.436149</td>\n",
       "      <td>-0.317276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ffd1576d2e1b</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>[-0.012024703, 0.016922273, 0.015488309, 0.002...</td>\n",
       "      <td>[0.058067385, 0.042484563, 0.012715496, 0.0067...</td>\n",
       "      <td>[0.022816774, 0.011155369, -0.0006411369, 0.02...</td>\n",
       "      <td>5.835000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.793538</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>-1.408180</td>\n",
       "      <td>-0.493603</td>\n",
       "      <td>-0.802727</td>\n",
       "      <td>-0.497868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ffe4a98093b2</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>[0.0091599105, -0.029818784, 0.0031730002, 0.0...</td>\n",
       "      <td>[-0.010795923, 0.025710443, -0.015630066, 0.01...</td>\n",
       "      <td>[0.012417577, -0.052821647, -0.0033073293, -0....</td>\n",
       "      <td>6.465116</td>\n",
       "      <td>9.454264</td>\n",
       "      <td>9.725611</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>4.627907</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "      <td>-0.464437</td>\n",
       "      <td>-0.124291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>[0.0067965747, 0.07661588, -0.009160591, 0.033...</td>\n",
       "      <td>[-0.013152148, 0.059951786, -0.0068048476, -0....</td>\n",
       "      <td>[0.0332336, 0.12647918, 0.0012254969, -0.01061...</td>\n",
       "      <td>6.554278</td>\n",
       "      <td>8.345316</td>\n",
       "      <td>8.238736</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>4.531646</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "      <td>0.257199</td>\n",
       "      <td>-0.150753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     000e8c3c7ddb    814d6b   \n",
       "1     0020ae56ffbf    ebad26   \n",
       "2     004e978e639e    3b9047   \n",
       "3     005ab0199905    3b9047   \n",
       "4     0070c9e7af47    814d6b   \n",
       "...            ...       ...   \n",
       "7160  ff7c7e70df07    ebad26   \n",
       "7161  ffc34d056498    3b9047   \n",
       "7162  ffd1576d2e1b    3b9047   \n",
       "7163  ffe4a98093b2    39c16e   \n",
       "7164  fffbccfd8a08    ebad26   \n",
       "\n",
       "                                        prompt_question  \\\n",
       "0     [0.054656938, -0.06503344, 0.011860348, -0.053...   \n",
       "1     [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "2     [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "3     [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "4     [0.054656938, -0.06503344, 0.011860348, -0.053...   \n",
       "...                                                 ...   \n",
       "7160  [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "7161  [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "7162  [-0.012024703, 0.016922273, 0.015488309, 0.002...   \n",
       "7163  [0.0091599105, -0.029818784, 0.0031730002, 0.0...   \n",
       "7164  [0.0067965747, 0.07661588, -0.009160591, 0.033...   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "0     [0.04722372, 0.06517054, 0.00032050064, -0.025...   \n",
       "1     [-0.013152148, 0.059951786, -0.0068048476, -0....   \n",
       "2     [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "3     [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "4     [0.04722372, 0.06517054, 0.00032050064, -0.025...   \n",
       "...                                                 ...   \n",
       "7160  [-0.013152148, 0.059951786, -0.0068048476, -0....   \n",
       "7161  [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "7162  [0.058067385, 0.042484563, 0.012715496, 0.0067...   \n",
       "7163  [-0.010795923, 0.025710443, -0.015630066, 0.01...   \n",
       "7164  [-0.013152148, 0.059951786, -0.0068048476, -0....   \n",
       "\n",
       "                                                   text   fk_grade  \\\n",
       "0     [0.041094355, -0.006460443, 0.008264857, -0.06...   9.002500   \n",
       "1     [0.033534568, 0.112103865, 0.013419032, 0.0166...   5.524444   \n",
       "2     [0.022079999, 0.030259458, 0.016786981, 0.0001...   9.238716   \n",
       "3     [0.041241955, -0.01394414, 0.015658101, 0.0315...   4.160522   \n",
       "4     [0.008337094, 0.04310772, 0.0132706165, -0.052...  10.254643   \n",
       "...                                                 ...        ...   \n",
       "7160  [0.035653163, 0.043147907, -0.030623915, -0.00...  12.250000   \n",
       "7161  [-0.035234254, 0.033364758, 0.02028155, 0.0068...   7.304138   \n",
       "7162  [0.022816774, 0.011155369, -0.0006411369, 0.02...   5.835000   \n",
       "7163  [0.012417577, -0.052821647, -0.0033073293, -0....   6.465116   \n",
       "7164  [0.0332336, 0.12647918, 0.0012254969, -0.01061...   6.554278   \n",
       "\n",
       "      gunning_fog       smog  lexical_density  avg_word_length  \\\n",
       "0       11.466667  11.208143         0.875000         5.312500   \n",
       "1        7.200000   3.129100         0.805556         4.166667   \n",
       "2       11.572072  11.374739         0.731183         5.456989   \n",
       "3        7.057391   7.554174         0.800000         6.200000   \n",
       "4       14.071429  12.540901         0.787500         5.712500   \n",
       "...           ...        ...              ...              ...   \n",
       "7160    15.015385  13.023867         0.823529         5.000000   \n",
       "7161     6.625287   7.793538         0.862069         6.034483   \n",
       "7162     7.333333   7.793538         0.923077         5.000000   \n",
       "7163     9.454264   9.725611         0.813953         4.627907   \n",
       "7164     8.345316   8.238736         0.772152         4.531646   \n",
       "\n",
       "      avg_sentence_length   content   wording  normalized_content  \\\n",
       "0               12.000000  0.205683  0.380538           -0.264772   \n",
       "1               18.000000 -0.548304  0.506755           -0.516101   \n",
       "2               15.416667  3.128928  4.231226            0.709643   \n",
       "3                4.600000 -0.210614 -0.471415           -0.403538   \n",
       "4               12.307692  3.272894  3.219757            0.757631   \n",
       "...                   ...       ...       ...                 ...   \n",
       "7160            26.000000  0.205683  0.380538           -0.264772   \n",
       "7161             7.250000 -0.308448  0.048171           -0.436149   \n",
       "7162            13.333333 -1.408180 -0.493603           -0.802727   \n",
       "7163            14.333333 -0.393310  0.627128           -0.464437   \n",
       "7164            13.166667  1.771596  0.547742            0.257199   \n",
       "\n",
       "      normalized_wording  \n",
       "0              -0.206487  \n",
       "1              -0.164415  \n",
       "2               1.077075  \n",
       "3              -0.490472  \n",
       "4               0.739919  \n",
       "...                  ...  \n",
       "7160           -0.206487  \n",
       "7161           -0.317276  \n",
       "7162           -0.497868  \n",
       "7163           -0.124291  \n",
       "7164           -0.150753  \n",
       "\n",
       "[7165 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_summaries_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194de095-ba2c-4ca2-bdf7-be3e9204b92a",
   "metadata": {},
   "source": [
    "### Serialize and deserialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e081d7c2-f824-4643-8769-e9e400f64552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_array(arr):\n",
    "    return arr.tobytes()\n",
    "    \n",
    "def deserialize_array(binary_string, dtype, shape):\n",
    "    return np.frombuffer(binary_string, dtype=dtype).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6664ef03-0b0e-45f3-87cf-e8f464015c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data['prompt_question'] = data['prompt_question'].apply(serialize_array)\n",
    "    data['prompt_text'] = data['prompt_text'].apply(serialize_array)\n",
    "    data['text'] = data['text'].apply(serialize_array)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "18e5be9f-43b1-4614-a6ed-676aaf632f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_summaries_train = preprocess_data(preprocess_summaries_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432a82c-ba06-41a9-b153-06eda8530afc",
   "metadata": {},
   "source": [
    "### Converting the pandas dataset to huggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7ff22dd7-c9eb-4dd5-95ac-2b0169d74aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(preprocess_summaries_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e55ee54-ca5f-46ab-93dc-c3c2988abcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': train_dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "72994f5b-f125-4640-b6c6-c4f25610dc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345a2ca4e9274280a7facacaf52b0444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/7165 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = DatasetDict(dataset)\n",
    "path = './data/hugging_face/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b311976-aa79-41db-997d-f2e8f6f1c1a1",
   "metadata": {},
   "source": [
    "### Test the HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80070679-e2df-490c-b8b2-55be5beb36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later you can load the entire DatasetDict back from disk like this\n",
    "dataset_dict = DatasetDict.load_from_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "16d10c37-4863-4434-a853-7b2a77a8d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['student_id', 'prompt_id', 'prompt_question', 'prompt_text', 'text', 'content', 'wording', 'normalized_content', 'normalized_wording'],\n",
      "        num_rows: 7165\n",
      "    })\n",
      "})\n",
      "\n",
      "(768,)\n",
      "\n",
      "(768,)\n",
      "\n",
      "(768,)\n",
      "\n",
      "0.205682506482641\n",
      "\n",
      "-0.2647724978391196\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict)\n",
    "print()\n",
    "print(deserialize_array(dataset_dict['train'][0]['prompt_question'], np.float32, (768)).shape)\n",
    "print()\n",
    "print(deserialize_array(dataset_dict['train'][0]['prompt_text'], np.float32, (768)).shape)\n",
    "print()\n",
    "print(deserialize_array(dataset_dict['train'][0]['text'], np.float32, (768)).shape)\n",
    "print()\n",
    "print(dataset_dict['train'][0]['content'])\n",
    "print()\n",
    "print(dataset_dict['train'][0]['normalized_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82417da-4b5e-4aeb-8c1a-3f465786b379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
